# Debugging Guide

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [Import ê´€ì  ë””ë²„ê¹…](#import-ê´€ì -ë””ë²„ê¹…)
3. [ë¡œì§ ê´€ì  ë””ë²„ê¹…](#ë¡œì§-ê´€ì -ë””ë²„ê¹…)
4. [Endpoint ê´€ì  ë””ë²„ê¹…](#endpoint-ê´€ì -ë””ë²„ê¹…)
5. [ì•„í‚¤í…ì²˜ì  ê´€ì  ë””ë²„ê¹…](#ì•„í‚¤í…ì²˜ì -ê´€ì -ë””ë²„ê¹…)
6. [ë°ì´í„°ë² ì´ìŠ¤ ê´€ì  ë””ë²„ê¹…](#ë°ì´í„°ë² ì´ìŠ¤-ê´€ì -ë””ë²„ê¹…)
7. [ë¹„ë™ê¸°/ë™ì‹œì„± ê´€ì  ë””ë²„ê¹…](#ë¹„ë™ê¸°ë™ì‹œì„±-ê´€ì -ë””ë²„ê¹…)
8. [í™˜ê²½/ì„¤ì • ê´€ì  ë””ë²„ê¹…](#í™˜ê²½ì„¤ì •-ê´€ì -ë””ë²„ê¹…)
9. [ìºì‹œ ê´€ì  ë””ë²„ê¹…](#ìºì‹œ-ê´€ì -ë””ë²„ê¹…)
10. [ë””ë²„ê¹… ë„êµ¬ ë° ê¸°ë²•](#ë””ë²„ê¹…-ë„êµ¬-ë°-ê¸°ë²•)
11. [ì²´í¬ë¦¬ìŠ¤íŠ¸](#ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## ê°œìš”

ë³¸ ë¬¸ì„œëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë””ë²„ê¹…í•˜ê¸° ìœ„í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. 
ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ì ‘ê·¼í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ì›ì¸ì„ íŒŒì•…í•˜ê³  í•´ê²°í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

### ë””ë²„ê¹… ê¸°ë³¸ ì›ì¹™

1. **ì²´ê³„ì  ì ‘ê·¼**: ë¬¸ì œë¥¼ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„
2. **ê°€ì„¤ ì„¤ì •**: ê°€ëŠ¥í•œ ì›ì¸ì„ ê°€ì„¤ë¡œ ì„¤ì •í•˜ê³  ê²€ì¦
3. **ì¦ê±° ìˆ˜ì§‘**: ë¡œê·¸, ì—ëŸ¬ ë©”ì‹œì§€, ìƒíƒœ ì •ë³´ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘
4. **ì¬í˜„ ê°€ëŠ¥ì„±**: ë¬¸ì œë¥¼ ì¬í˜„í•  ìˆ˜ ìˆëŠ” í™˜ê²½ê³¼ ì‹œë‚˜ë¦¬ì˜¤ í™•ë³´
5. **ì ì§„ì  ì¶•ì†Œ**: ë¬¸ì œ ë²”ìœ„ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¢í˜€ê°€ë©° ì›ì¸ íŒŒì•…

### ë””ë²„ê¹… í”„ë¡œì„¸ìŠ¤

```
1. ë¬¸ì œ ì¸ì‹ ë° ì¬í˜„
   â†“
2. ì¦ìƒ ê´€ì°° ë° ì •ë³´ ìˆ˜ì§‘
   â†“
3. ê°€ì„¤ ì„¤ì • (Import â†’ ë¡œì§ â†’ Endpoint â†’ ì•„í‚¤í…ì²˜ â†’ DB â†’ ë¹„ë™ê¸° â†’ í™˜ê²½ â†’ ìºì‹œ ìˆœì„œ)
   â†“
4. ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
   â†“
5. í•´ê²° ë° ê²€ì¦
   â†“
6. ë¬¸ì„œí™” ë° ì˜ˆë°© ì¡°ì¹˜
```

---

## Import ê´€ì  ë””ë²„ê¹…

Import ë¬¸ì œëŠ” ì½”ë“œ ì‹¤í–‰ ì „ ë‹¨ê³„ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¡œ, ê°€ì¥ ë¨¼ì € í™•ì¸í•´ì•¼ í•  ë¶€ë¶„ì…ë‹ˆë‹¤.

### 1. Import ì—ëŸ¬ ìœ í˜•

#### 1.1 ModuleNotFoundError

**ì¦ìƒ**
```python
ModuleNotFoundError: No module named 'some_module'
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ëª¨ë“ˆì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ê°€? (ìƒëŒ€ ê²½ë¡œ vs ì ˆëŒ€ ê²½ë¡œ)
- [ ] `__init__.py` íŒŒì¼ì´ í•„ìš”í•œ ìœ„ì¹˜ì— ìˆëŠ”ê°€?
- [ ] Python ê²½ë¡œ(PYTHONPATH)ì— ëª¨ë“ˆì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
- [ ] ê°€ìƒ í™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆê³  í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ê°€?

**ë””ë²„ê¹… ë°©ë²•**

```python
# 1. ëª¨ë“ˆ ê²½ë¡œ í™•ì¸
import sys
print(sys.path)

# 2. ëª¨ë“ˆ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
import importlib.util
spec = importlib.util.find_spec("some_module")
print(spec.origin if spec else "Module not found")

# 3. ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ í™•ì¸
# ì˜ëª»ëœ ì˜ˆ
from ..parent import something  # ìƒìœ„ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°

# ì˜¬ë°”ë¥¸ ì˜ˆ
from app.parent import something  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
```

#### 1.2 ImportError (ìˆœí™˜ ì°¸ì¡°)

**ì¦ìƒ**
```python
ImportError: cannot import name 'X' from partially initialized module 'Y'
```

**ì›ì¸**
- ëª¨ë“ˆ Aê°€ ëª¨ë“ˆ Bë¥¼ importí•˜ê³ , ëª¨ë“ˆ Bê°€ ë‹¤ì‹œ ëª¨ë“ˆ Aë¥¼ importí•˜ëŠ” ê²½ìš°
- ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì„œë¡œ ì˜ì¡´í•˜ëŠ” ì½”ë“œ ì‹¤í–‰

**í•´ê²° ë°©ë²•**

```python
# ë¬¸ì œ ì½”ë“œ
# module_a.py
from module_b import ClassB

class ClassA:
    def use_b(self):
        return ClassB()

# module_b.py
from module_a import ClassA  # ìˆœí™˜ ì°¸ì¡°!

class ClassB:
    def use_a(self):
        return ClassA()

# í•´ê²° ë°©ë²• 1: ì§€ì—° import (Lazy Import)
# module_b.py
class ClassB:
    def use_a(self):
        from module_a import ClassA  # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import
        return ClassA()

# í•´ê²° ë°©ë²• 2: íƒ€ì… íŒíŠ¸ë§Œ ì‚¬ìš© (Python 3.7+)
# module_b.py
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from module_a import ClassA

class ClassB:
    def use_a(self) -> 'ClassA':
        from module_a import ClassA
        return ClassA()

# í•´ê²° ë°©ë²• 3: ì•„í‚¤í…ì²˜ ì¬ì„¤ê³„
# ê³µí†µ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë³„ë„ ëª¨ë“ˆë¡œ ë¶„ë¦¬
```

#### 1.3 AttributeError (Import í›„ ì†ì„± ì ‘ê·¼ ì‹¤íŒ¨)

**ì¦ìƒ**
```python
AttributeError: module 'X' has no attribute 'Y'
```

**ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ëª¨ë“ˆì´ ì˜¬ë°”ë¥´ê²Œ importë˜ì—ˆëŠ”ê°€?
- [ ] í•´ë‹¹ ì†ì„±/í•¨ìˆ˜/í´ë˜ìŠ¤ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€?
- [ ] ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€? (ëŒ€ì†Œë¬¸ì, ì–¸ë”ìŠ¤ì½”ì–´ ë“±)
- [ ] `__all__`ì— ì˜í•´ exportê°€ ì œí•œë˜ì§€ ì•Šì•˜ëŠ”ê°€?

**ë””ë²„ê¹… ë°©ë²•**

```python
# 1. ëª¨ë“ˆ ë‚´ìš© í™•ì¸
import some_module
print(dir(some_module))  # ëª¨ë“ˆì˜ ëª¨ë“  ì†ì„± í™•ì¸
print(some_module.__dict__)  # ëª¨ë“ˆ ë”•ì…”ë„ˆë¦¬ í™•ì¸

# 2. __all__ í™•ì¸
print(some_module.__all__)  # exportëœ í•­ëª© í™•ì¸

# 3. íƒ€ì… í™•ì¸
import inspect
print(inspect.getmembers(some_module))
```

#### 1.4 íŒ¨í‚¤ì§€ ë²„ì „ ì¶©ëŒ

**ì¦ìƒ**
- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë™ì‘
- íƒ€ì… ë¶ˆì¼ì¹˜
- ë©”ì„œë“œ/ì†ì„±ì´ ì—†ë‹¤ëŠ” ì—ëŸ¬

**ì²´í¬ë¦¬ìŠ¤íŠ¸**
- [ ] ì—¬ëŸ¬ ë²„ì „ì˜ ë™ì¼ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ê°€?
- [ ] ì˜ì¡´ì„± íŠ¸ë¦¬ì— ì¶©ëŒì´ ìˆëŠ”ê°€?
- [ ] ê°€ìƒ í™˜ê²½ì´ ê²©ë¦¬ë˜ì–´ ìˆëŠ”ê°€?

**ë””ë²„ê¹… ë°©ë²•**

```python
# 1. íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸
import some_package
print(some_package.__version__)

# 2. íŒ¨í‚¤ì§€ ìœ„ì¹˜ í™•ì¸
import some_package
print(some_package.__file__)

# 3. ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ í™•ì¸ (í„°ë¯¸ë„)
# pip list | grep package_name
# pip show package_name
```

### 2. Import ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

#### 2.1 ê¸°ë³¸ í™•ì¸ ì‚¬í•­

```
â–¡ Python ë²„ì „ì´ ìš”êµ¬ì‚¬í•­ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?
â–¡ ê°€ìƒ í™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ê°€?
â–¡ requirements.txt / pyproject.tomlì˜ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ê°€?
â–¡ IDEì˜ Python ì¸í„°í”„ë¦¬í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ê°€?
```

#### 2.2 ê²½ë¡œ ê´€ë ¨ í™•ì¸ ì‚¬í•­

```
â–¡ í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ PYTHONPATHì— í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ìƒëŒ€ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ê°€? (.., . ì˜ ì‚¬ìš©)
â–¡ __init__.py íŒŒì¼ì´ í•„ìš”í•œ ëª¨ë“  ë””ë ‰í† ë¦¬ì— ìˆëŠ”ê°€?
â–¡ íŒ¨í‚¤ì§€ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ê°€?
```

#### 2.3 ì˜ì¡´ì„± ê´€ë ¨ í™•ì¸ ì‚¬í•­

```
â–¡ ìˆœí™˜ ì°¸ì¡°ê°€ ì—†ëŠ”ê°€?
â–¡ ì˜ì¡´ì„± ë²„ì „ì´ í˜¸í™˜ë˜ëŠ”ê°€?
â–¡ ì˜ì¡´ì„± ì¶©ëŒì´ ì—†ëŠ”ê°€?
â–¡ ì„ íƒì  ì˜ì¡´ì„±(optional dependencies)ì´ í•„ìš”í•œê°€?
```

### 3. Import ë””ë²„ê¹… ë„êµ¬

#### 3.1 Python ë‚´ì¥ ë„êµ¬

```python
# importlibë¥¼ ì‚¬ìš©í•œ ë™ì  import ë””ë²„ê¹…
import importlib
import importlib.util

# ëª¨ë“ˆ ë¡œë“œ í™•ì¸
try:
    module = importlib.import_module('some_module')
    print(f"Module loaded: {module.__file__}")
except ImportError as e:
    print(f"Import failed: {e}")

# ëª¨ë“ˆ ì¬ë¡œë“œ (ê°œë°œ ì¤‘ ìœ ìš©)
importlib.reload(module)
```

#### 3.2 ì™¸ë¶€ ë„êµ¬

```bash
# pipdeptree: ì˜ì¡´ì„± íŠ¸ë¦¬ í™•ì¸
pip install pipdeptree
pipdeptree

# pip-check: ì—…ë°ì´íŠ¸ ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€ í™•ì¸
pip install pip-check
pip-check

# import-linter: import ê·œì¹™ ê²€ì‚¬
pip install import-linter
lint-imports
```

---

## ë¡œì§ ê´€ì  ë””ë²„ê¹…

ë¡œì§ ê´€ì  ë””ë²„ê¹…ì€ ì½”ë“œì˜ ì‹¤í–‰ íë¦„ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

### 1. ë¡œì§ ì—ëŸ¬ ìœ í˜•

#### 1.1 ì œì–´ íë¦„ ë¬¸ì œ

**ì¦ìƒ**
- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë¶„ê¸°ë¡œ ì§„ì…
- ë£¨í”„ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë™ì‘
- ì¡°ê±´ë¬¸ì´ í•­ìƒ True/False

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¬¸ì œ ì½”ë“œ ì˜ˆì‹œ
def process_order(order):
    if order.status == "pending":  # í•­ìƒ False?
        return handle_pending(order)
    elif order.status == "completed":
        return handle_completed(order)
    else:
        return handle_unknown(order)

# ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
def process_order(order):
    # 1. ì…ë ¥ ê°’ í™•ì¸
    print(f"DEBUG: order.status = {order.status}")
    print(f"DEBUG: type(order.status) = {type(order.status)}")
    print(f"DEBUG: order.status == 'pending' = {order.status == 'pending'}")
    
    # 2. ì¡°ê±´ë¬¸ ë‹¨ê³„ë³„ í™•ì¸
    if order.status == "pending":
        print("DEBUG: Entering pending branch")
        return handle_pending(order)
    elif order.status == "completed":
        print("DEBUG: Entering completed branch")
        return handle_completed(order)
    else:
        print(f"DEBUG: Entering unknown branch with status: {order.status}")
        return handle_unknown(order)

# ê°œì„ ëœ ë²„ì „: íƒ€ì… ì•ˆì „ì„± í™•ë³´
def process_order(order):
    status = str(order.status).lower().strip()  # ì •ê·œí™”
    print(f"DEBUG: normalized status = '{status}'")
    
    if status == "pending":
        return handle_pending(order)
    elif status == "completed":
        return handle_completed(order)
    else:
        raise ValueError(f"Unknown order status: {order.status}")
```

#### 1.2 ë°ì´í„° ë³€í™˜ ë¬¸ì œ

**ì¦ìƒ**
- ë°ì´í„° íƒ€ì… ë¶ˆì¼ì¹˜
- None ê°’ ì²˜ë¦¬ ì‹¤íŒ¨
- ë°ì´í„° í¬ë§· ì˜¤ë¥˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¬¸ì œ ì½”ë“œ ì˜ˆì‹œ
def calculate_total(items):
    total = 0
    for item in items:
        total += item.price * item.quantity
    return total

# ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
def calculate_total(items):
    print(f"DEBUG: items type = {type(items)}")
    print(f"DEBUG: items = {items}")
    
    total = 0
    for idx, item in enumerate(items):
        print(f"DEBUG: item[{idx}] = {item}")
        print(f"DEBUG: item type = {type(item)}")
        print(f"DEBUG: item.price = {item.price}, type = {type(item.price)}")
        print(f"DEBUG: item.quantity = {item.quantity}, type = {type(item.quantity)}")
        
        # None ì²´í¬
        if item.price is None:
            print(f"WARNING: item[{idx}].price is None")
            continue
        if item.quantity is None:
            print(f"WARNING: item[{idx}].quantity is None")
            continue
        
        item_total = item.price * item.quantity
        print(f"DEBUG: item[{idx}] total = {item_total}")
        total += item_total
    
    print(f"DEBUG: final total = {total}")
    return total

# ê°œì„ ëœ ë²„ì „: ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°
def calculate_total(items):
    if not items:
        return 0
    
    total = 0
    for item in items:
        try:
            price = float(item.price) if item.price is not None else 0
            quantity = int(item.quantity) if item.quantity is not None else 0
            total += price * quantity
        except (ValueError, TypeError) as e:
            logger.warning(f"Invalid item data: {item}, error: {e}")
            continue
    
    return total
```

#### 1.3 ìƒíƒœ ê´€ë¦¬ ë¬¸ì œ

**ì¦ìƒ**
- ìƒíƒœê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„
- ìƒíƒœ ë³€ê²½ì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ
- ë™ì‹œì„± ë¬¸ì œ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¬¸ì œ ì½”ë“œ ì˜ˆì‹œ
class OrderProcessor:
    def __init__(self):
        self.processing = False
    
    def process(self, order):
        if self.processing:
            return "Already processing"
        self.processing = True
        # ... ì²˜ë¦¬ ë¡œì§ ...
        self.processing = False

# ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
class OrderProcessor:
    def __init__(self):
        self.processing = False
        self._state_history = []  # ìƒíƒœ ë³€ê²½ ì´ë ¥ ì¶”ì 
    
    def _log_state(self, action, value):
        import time
        self._state_history.append({
            'time': time.time(),
            'action': action,
            'value': value,
            'stack': traceback.format_stack()
        })
        print(f"DEBUG: State change - {action}: {value}")
    
    def process(self, order):
        self._log_state("check_processing", self.processing)
        
        if self.processing:
            print("DEBUG: Already processing, returning early")
            return "Already processing"
        
        self._log_state("set_processing", True)
        self.processing = True
        
        try:
            # ... ì²˜ë¦¬ ë¡œì§ ...
            result = self._do_process(order)
            return result
        finally:
            self._log_state("set_processing", False)
            self.processing = False
```

#### 1.4 ì˜ˆì™¸ ì²˜ë¦¬ ë¬¸ì œ

**ì¦ìƒ**
- ì˜ˆì™¸ê°€ ì¡íˆì§€ ì•ŠìŒ
- ì˜ëª»ëœ ì˜ˆì™¸ ì²˜ë¦¬ë¡œ ì¸í•œ ë°ì´í„° ì†ì‹¤
- ì˜ˆì™¸ ì •ë³´ ì†ì‹¤

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¬¸ì œ ì½”ë“œ ì˜ˆì‹œ
def process_data(data):
    try:
        result = risky_operation(data)
        return result
    except:
        return None  # ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ

# ê°œì„ ëœ ë²„ì „
def process_data(data):
    try:
        result = risky_operation(data)
        return result
    except SpecificError as e:
        logger.error(f"Specific error in process_data: {e}", exc_info=True)
        raise
    except ValueError as e:
        logger.warning(f"Invalid data format: {data}, error: {e}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error in process_data: {e}", exc_info=True)
        raise RuntimeError(f"Failed to process data: {e}") from e
```

### 2. ë¡œì§ ë””ë²„ê¹… ì „ëµ

#### 2.1 ë‹¨ê³„ë³„ ì‹¤í–‰ (Step-by-step)

```python
# ë³µì¡í•œ ë¡œì§ì„ ë‹¨ê³„ë³„ë¡œ ë¶„ë¦¬
def complex_operation(data):
    # Step 1: ì…ë ¥ ê²€ì¦
    validated_data = validate_input(data)
    print(f"Step 1 - Validated: {validated_data}")
    
    # Step 2: ë°ì´í„° ë³€í™˜
    transformed_data = transform_data(validated_data)
    print(f"Step 2 - Transformed: {transformed_data}")
    
    # Step 3: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    result = apply_business_logic(transformed_data)
    print(f"Step 3 - Result: {result}")
    
    # Step 4: ê²°ê³¼ ê²€ì¦
    validated_result = validate_result(result)
    print(f"Step 4 - Final: {validated_result}")
    
    return validated_result
```

#### 2.2 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

```python
# ë¬¸ì œë¥¼ ì¬í˜„í•˜ëŠ” ìµœì†Œí•œì˜ í…ŒìŠ¤íŠ¸ ì‘ì„±
def test_problematic_case():
    # ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ì…ë ¥
    problematic_input = {...}
    
    # ì˜ˆìƒ ê²°ê³¼
    expected_result = {...}
    
    # ì‹¤ì œ ì‹¤í–‰
    actual_result = function_under_test(problematic_input)
    
    # ë¹„êµ
    assert actual_result == expected_result, \
        f"Expected {expected_result}, got {actual_result}"
```

#### 2.3 ë¡œê·¸ ì „ëµ

```python
import logging

# ë¡œê·¸ ë ˆë²¨ë³„ ì‚¬ìš©
logger = logging.getLogger(__name__)

def business_logic(data):
    logger.debug(f"Input data: {data}")  # ìƒì„¸ ì •ë³´
    
    if not data:
        logger.warning("Empty data received")  # ê²½ê³ 
        return None
    
    try:
        result = process(data)
        logger.info(f"Processed successfully: {result}")  # ì •ìƒ íë¦„
        return result
    except Exception as e:
        logger.error(f"Processing failed: {e}", exc_info=True)  # ì—ëŸ¬
        raise
```

### 3. ë¡œì§ ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ì…ë ¥ ê°’ì´ ì˜ˆìƒí•œ í˜•ì‹/ë²”ìœ„ì¸ê°€?
â–¡ ëª¨ë“  ë¶„ê¸° ê²½ë¡œê°€ í…ŒìŠ¤íŠ¸ë˜ì—ˆëŠ”ê°€?
â–¡ ì—£ì§€ ì¼€ì´ìŠ¤(ë¹ˆ ê°’, None, ìµœëŒ€/ìµœì†Œ ê°’)ê°€ ì²˜ë¦¬ë˜ëŠ”ê°€?
â–¡ ë£¨í”„ì˜ ì¢…ë£Œ ì¡°ê±´ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ ìƒíƒœ ë³€ê²½ì´ ì˜ˆìƒëŒ€ë¡œ ì¼ì–´ë‚˜ëŠ”ê°€?
â–¡ ì˜ˆì™¸ ìƒí™©ì´ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ê°€?
â–¡ ë™ì‹œì„± ë¬¸ì œê°€ ì—†ëŠ”ê°€? (ë©€í‹°ìŠ¤ë ˆë“œ/ë¹„ë™ê¸° í™˜ê²½)
â–¡ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±ì´ ì—†ëŠ”ê°€?
```

---

## Endpoint ê´€ì  ë””ë²„ê¹…

Endpoint ë””ë²„ê¹…ì€ API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤. 
ìš”ì²­ë¶€í„° ì‘ë‹µê¹Œì§€ì˜ ì „ì²´ íë¦„ì„ ì¶”ì í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. Endpoint ì—ëŸ¬ ìœ í˜•

#### 1.1 ìš”ì²­ ê²€ì¦ ì‹¤íŒ¨

**ì¦ìƒ**
- 400 Bad Request
- 422 Unprocessable Entity
- ê²€ì¦ ì—ëŸ¬ ë©”ì‹œì§€

**ë””ë²„ê¹… ë°©ë²•**

```python
# FastAPI ì˜ˆì‹œ
from fastapi import FastAPI, Request
from fastapi.exceptions import RequestValidationError
import logging

logger = logging.getLogger(__name__)

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    # ìš”ì²­ ì •ë³´ ë¡œê¹…
    logger.error(f"Validation error on {request.method} {request.url}")
    logger.error(f"Headers: {dict(request.headers)}")
    logger.error(f"Query params: {dict(request.query_params)}")
    
    # ìš”ì²­ ë³¸ë¬¸ ë¡œê¹… (ë³´ì•ˆ ì£¼ì˜)
    try:
        body = await request.body()
        logger.error(f"Request body: {body.decode()}")
    except Exception as e:
        logger.error(f"Could not read body: {e}")
    
    # ê²€ì¦ ì—ëŸ¬ ìƒì„¸ ì •ë³´
    logger.error(f"Validation errors: {exc.errors()}")
    
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": body.decode() if body else None}
    )

# ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def log_requests(request: Request, call_next):
    import time
    start_time = time.time()
    
    # ìš”ì²­ ì •ë³´ ë¡œê¹…
    logger.info(f"Request: {request.method} {request.url.path}")
    logger.debug(f"Query params: {dict(request.query_params)}")
    logger.debug(f"Headers: {dict(request.headers)}")
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    logger.info(f"Response: {response.status_code} - {process_time:.3f}s")
    
    return response
```

#### 1.2 ì¸ì¦/ì¸ê°€ ì‹¤íŒ¨

**ì¦ìƒ**
- 401 Unauthorized
- 403 Forbidden
- í† í° ë§Œë£Œ/ë¬´íš¨

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì¸ì¦ ë””ë²„ê¹…
def authenticate_request(request: Request):
    # 1. í—¤ë” í™•ì¸
    auth_header = request.headers.get("Authorization")
    logger.debug(f"Auth header present: {auth_header is not None}")
    
    if not auth_header:
        logger.warning("No Authorization header")
        raise HTTPException(status_code=401, detail="Missing authorization")
    
    # 2. í† í° í˜•ì‹ í™•ì¸
    try:
        scheme, token = auth_header.split(" ", 1)
        logger.debug(f"Auth scheme: {scheme}, token length: {len(token)}")
    except ValueError:
        logger.error(f"Invalid auth header format: {auth_header}")
        raise HTTPException(status_code=401, detail="Invalid authorization format")
    
    # 3. í† í° ê²€ì¦
    try:
        payload = verify_token(token)
        logger.debug(f"Token payload: {payload}")
        return payload
    except TokenExpiredError as e:
        logger.warning(f"Token expired: {e}")
        raise HTTPException(status_code=401, detail="Token expired")
    except InvalidTokenError as e:
        logger.error(f"Invalid token: {e}")
        raise HTTPException(status_code=401, detail="Invalid token")
```

#### 1.3 ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì—ëŸ¬

**ì¦ìƒ**
- 500 Internal Server Error
- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ
- ë°ì´í„° ë¶ˆì¼ì¹˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì—”ë“œí¬ì¸íŠ¸ ì „ì²´ íë¦„ ì¶”ì 
@app.post("/orders")
async def create_order(order_data: OrderCreate, request: Request):
    request_id = request.state.request_id  # ìš”ì²­ ID ì¶”ì 
    
    logger.info(f"[{request_id}] Creating order: {order_data}")
    
    try:
        # Step 1: ì…ë ¥ ê²€ì¦
        logger.debug(f"[{request_id}] Step 1: Validating input")
        validated_data = validate_order_data(order_data)
        logger.debug(f"[{request_id}] Validation passed: {validated_data}")
        
        # Step 2: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
        logger.debug(f"[{request_id}] Step 2: Checking business rules")
        business_errors = check_business_rules(validated_data)
        if business_errors:
            logger.warning(f"[{request_id}] Business rule violations: {business_errors}")
            raise HTTPException(status_code=400, detail=business_errors)
        
        # Step 3: ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…
        logger.debug(f"[{request_id}] Step 3: Saving to database")
        order = await save_order(validated_data)
        logger.info(f"[{request_id}] Order created: {order.id}")
        
        # Step 4: ë¶€ê°€ ì‘ì—… (ì´ë²¤íŠ¸ ë°œí–‰ ë“±)
        logger.debug(f"[{request_id}] Step 4: Publishing events")
        await publish_order_created_event(order)
        
        return order
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[{request_id}] Unexpected error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")
```

#### 1.4 ì‘ë‹µ í˜•ì‹ ë¬¸ì œ

**ì¦ìƒ**
- ì§ë ¬í™” ì—ëŸ¬
- íƒ€ì… ë¶ˆì¼ì¹˜
- ëˆ„ë½ëœ í•„ë“œ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì‘ë‹µ ì§ë ¬í™” ë””ë²„ê¹…
def serialize_response(data):
    try:
        # Pydantic ëª¨ë¸ì¸ ê²½ìš°
        if hasattr(data, 'dict'):
            serialized = data.dict()
            logger.debug(f"Serialized data: {serialized}")
            return serialized
        
        # ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
        if isinstance(data, dict):
            # None ê°’ í™•ì¸
            none_keys = [k for k, v in data.items() if v is None]
            if none_keys:
                logger.warning(f"None values in response: {none_keys}")
            return data
        
        # ê¸°íƒ€ íƒ€ì…
        logger.warning(f"Unexpected response type: {type(data)}")
        return str(data)
        
    except Exception as e:
        logger.error(f"Serialization error: {e}", exc_info=True)
        raise
```

### 2. Endpoint ë””ë²„ê¹… ì „ëµ

#### 2.1 ìš”ì²­/ì‘ë‹µ ë¡œê¹…

```python
# ìƒì„¸í•œ ìš”ì²­/ì‘ë‹µ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def detailed_logging(request: Request, call_next):
    import uuid
    import json
    import time
    
    request_id = str(uuid.uuid4())
    request.state.request_id = request_id
    
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹…
    log_data = {
        "request_id": request_id,
        "method": request.method,
        "url": str(request.url),
        "path": request.url.path,
        "query_params": dict(request.query_params),
        "headers": dict(request.headers),
    }
    
    # ë³¸ë¬¸ ë¡œê¹… (í¬ê¸° ì œí•œ)
    try:
        body = await request.body()
        if len(body) < 10000:  # 10KB ì œí•œ
            log_data["body"] = body.decode()
        else:
            log_data["body_size"] = len(body)
    except Exception:
        pass
    
    logger.info(f"Request: {json.dumps(log_data, indent=2)}")
    
    # ì‘ë‹µ ì²˜ë¦¬
    response = await call_next(request)
    
    process_time = time.time() - start_time
    
    # ì‘ë‹µ ë¡œê¹…
    response_log = {
        "request_id": request_id,
        "status_code": response.status_code,
        "process_time": f"{process_time:.3f}s",
    }
    
    logger.info(f"Response: {json.dumps(response_log, indent=2)}")
    
    return response
```

#### 2.2 ì—ëŸ¬ í•¸ë“¤ë§

```python
# ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    request_id = getattr(request.state, 'request_id', 'unknown')
    
    logger.error(
        f"[{request_id}] Unhandled exception: {exc}",
        exc_info=True,
        extra={
            "request_id": request_id,
            "method": request.method,
            "url": str(request.url),
        }
    )
    
    # í”„ë¡œë•ì…˜ì—ì„œëŠ” ìƒì„¸ ì •ë³´ ìˆ¨ê¹€
    if settings.DEBUG:
        return JSONResponse(
            status_code=500,
            content={
                "error": str(exc),
                "type": type(exc).__name__,
                "request_id": request_id,
            }
        )
    else:
        return JSONResponse(
            status_code=500,
            content={
                "error": "Internal server error",
                "request_id": request_id,
            }
        )
```

#### 2.3 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì„±ëŠ¥ ì¶”ì  ë°ì½”ë ˆì´í„°
import time
from functools import wraps

def track_performance(threshold_seconds=1.0):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                elapsed = time.time() - start_time
                
                if elapsed > threshold_seconds:
                    logger.warning(
                        f"Slow endpoint: {func.__name__} took {elapsed:.3f}s "
                        f"(threshold: {threshold_seconds}s)"
                    )
                else:
                    logger.debug(f"{func.__name__} took {elapsed:.3f}s")
        
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@app.get("/slow-endpoint")
@track_performance(threshold_seconds=0.5)
async def slow_endpoint():
    # ... ë¡œì§ ...
    pass
```

### 3. Endpoint ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ìš”ì²­ì´ ì˜¬ë°”ë¥¸ HTTP ë©”ì„œë“œë¡œ ì „ì†¡ë˜ì—ˆëŠ”ê°€?
â–¡ ìš”ì²­ í—¤ë”ê°€ ì˜¬ë°”ë¥¸ê°€? (Content-Type, Authorization ë“±)
â–¡ ìš”ì²­ ë³¸ë¬¸ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ê°€? (JSON, Form ë“±)
â–¡ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ ì˜¬ë°”ë¥¸ê°€?
â–¡ ê²½ë¡œ íŒŒë¼ë¯¸í„°ê°€ ì˜¬ë°”ë¥¸ê°€?
â–¡ ì¸ì¦ í† í°ì´ ìœ íš¨í•œê°€?
â–¡ ê¶Œí•œì´ ì¶©ë¶„í•œê°€?
â–¡ ì…ë ¥ ê²€ì¦ì´ í†µê³¼í–ˆëŠ”ê°€?
â–¡ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ì´ í†µê³¼í–ˆëŠ”ê°€?
â–¡ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì´ ì„±ê³µí–ˆëŠ”ê°€?
â–¡ ì™¸ë¶€ ì„œë¹„ìŠ¤ í˜¸ì¶œì´ ì„±ê³µí–ˆëŠ”ê°€?
â–¡ ì‘ë‹µ ì§ë ¬í™”ê°€ ì„±ê³µí–ˆëŠ”ê°€?
â–¡ ì‘ë‹µ ìƒíƒœ ì½”ë“œê°€ ì˜¬ë°”ë¥¸ê°€?
â–¡ CORS ì„¤ì •ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ Rate limitingì— ê±¸ë¦¬ì§€ ì•Šì•˜ëŠ”ê°€?
```

### 4. API í…ŒìŠ¤íŠ¸ ë„êµ¬ í™œìš©

#### 4.1 cURLì„ ì‚¬ìš©í•œ ë””ë²„ê¹…

```bash
# ê¸°ë³¸ ìš”ì²­
curl -X POST http://localhost:8000/api/orders \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer token" \
  -d '{"item_id": 123, "quantity": 2}'

# ìƒì„¸ ì •ë³´ ì¶œë ¥
curl -v -X POST http://localhost:8000/api/orders \
  -H "Content-Type: application/json" \
  -d '{"item_id": 123}'

# ì‘ë‹µ í—¤ë”ë§Œ í™•ì¸
curl -I http://localhost:8000/api/orders

# íƒ€ì„ì•„ì›ƒ ì„¤ì •
curl --max-time 10 http://localhost:8000/api/orders
```

#### 4.2 HTTPieë¥¼ ì‚¬ìš©í•œ ë””ë²„ê¹…

```bash
# ê¸°ë³¸ ìš”ì²­
http POST localhost:8000/api/orders \
  Authorization:"Bearer token" \
  item_id=123 quantity=2

# ìƒì„¸ ì¶œë ¥
http -v POST localhost:8000/api/orders item_id=123

# ì‘ë‹µ í—¤ë” í™•ì¸
http --headers GET localhost:8000/api/orders
```

---

## ì•„í‚¤í…ì²˜ì  ê´€ì  ë””ë²„ê¹…

ì•„í‚¤í…ì²˜ì  ê´€ì  ë””ë²„ê¹…ì€ ì‹œìŠ¤í…œ ì „ì²´ì˜ êµ¬ì¡°ì™€ ì»´í¬ë„ŒíŠ¸ ê°„ ìƒí˜¸ì‘ìš©ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

### 1. ì•„í‚¤í…ì²˜ ë¬¸ì œ ìœ í˜•

#### 1.1 ì„œë¹„ìŠ¤ ê°„ í†µì‹  ë¬¸ì œ

**ì¦ìƒ**
- íƒ€ì„ì•„ì›ƒ
- ì—°ê²° ì‹¤íŒ¨
- ë°ì´í„° ë¶ˆì¼ì¹˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì„œë¹„ìŠ¤ ê°„ í†µì‹  ì¶”ì 
import time
import logging
from typing import Optional

logger = logging.getLogger(__name__)

class ServiceClient:
    def __init__(self, service_name: str, base_url: str):
        self.service_name = service_name
        self.base_url = base_url
    
    async def call(self, endpoint: str, method: str = "GET", **kwargs):
        url = f"{self.base_url}/{endpoint}"
        request_id = kwargs.pop('request_id', None)
        
        logger.info(
            f"[{request_id}] Calling {self.service_name}: {method} {url}",
            extra={
                "service": self.service_name,
                "method": method,
                "url": url,
                "request_id": request_id,
            }
        )
        
        start_time = time.time()
        
        try:
            # ìš”ì²­ ì „ ìƒíƒœ í™•ì¸
            logger.debug(f"[{request_id}] Request params: {kwargs}")
            
            # ì‹¤ì œ í˜¸ì¶œ
            response = await self._make_request(method, url, **kwargs)
            
            elapsed = time.time() - start_time
            
            logger.info(
                f"[{request_id}] {self.service_name} responded: "
                f"{response.status_code} in {elapsed:.3f}s"
            )
            
            return response
            
        except TimeoutError as e:
            elapsed = time.time() - start_time
            logger.error(
                f"[{request_id}] {self.service_name} timeout after {elapsed:.3f}s: {e}",
                extra={
                    "service": self.service_name,
                    "error": "timeout",
                    "duration": elapsed,
                }
            )
            raise
            
        except ConnectionError as e:
            logger.error(
                f"[{request_id}] {self.service_name} connection error: {e}",
                extra={
                    "service": self.service_name,
                    "error": "connection_error",
                }
            )
            raise
            
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(
                f"[{request_id}] {self.service_name} error after {elapsed:.3f}s: {e}",
                exc_info=True,
                extra={
                    "service": self.service_name,
                    "error": type(e).__name__,
                    "duration": elapsed,
                }
            )
            raise
```

#### 1.2 ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ

**ì¦ìƒ**
- ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ê°„ ë°ì´í„° ë¶ˆì¼ì¹˜
- ìºì‹œì™€ DB ë¶ˆì¼ì¹˜
- ì´ë²¤íŠ¸ ìˆœì„œ ë¬¸ì œ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¶„ì‚° íŠ¸ë ˆì´ì‹±
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import ConsoleSpanExporter

tracer = trace.get_tracer(__name__)

async def process_order_with_tracing(order_id: str):
    with tracer.start_as_current_span("process_order") as span:
        span.set_attribute("order_id", order_id)
        
        # Step 1: ì£¼ë¬¸ ì¡°íšŒ
        with tracer.start_as_current_span("fetch_order") as fetch_span:
            order = await fetch_order(order_id)
            fetch_span.set_attribute("order.status", order.status)
            span.add_event("Order fetched", {"order_id": order_id})
        
        # Step 2: ì¬ê³  í™•ì¸
        with tracer.start_as_current_span("check_inventory") as inv_span:
            inventory = await check_inventory(order.items)
            inv_span.set_attribute("inventory.available", inventory.available)
            span.add_event("Inventory checked")
        
        # Step 3: ê²°ì œ ì²˜ë¦¬
        with tracer.start_as_current_span("process_payment") as pay_span:
            payment = await process_payment(order)
            pay_span.set_attribute("payment.status", payment.status)
            span.add_event("Payment processed", {"payment_id": payment.id})
        
        # Step 4: ì£¼ë¬¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        with tracer.start_as_current_span("update_order") as update_span:
            await update_order_status(order_id, "confirmed")
            update_span.set_attribute("new_status", "confirmed")
            span.add_event("Order confirmed")
        
        return order
```

#### 1.3 ë¦¬ì†ŒìŠ¤ ê²½í•© ë¬¸ì œ

**ì¦ìƒ**
- ë°ë“œë½
- ì„±ëŠ¥ ì €í•˜
- ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ëª¨ë‹ˆí„°ë§
import psutil
import threading
import time

class ResourceMonitor:
    def __init__(self):
        self.monitoring = False
        self.thread = None
    
    def start(self):
        self.monitoring = True
        self.thread = threading.Thread(target=self._monitor, daemon=True)
        self.thread.start()
    
    def stop(self):
        self.monitoring = False
        if self.thread:
            self.thread.join()
    
    def _monitor(self):
        while self.monitoring:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory = psutil.virtual_memory()
            
            # ë””ìŠ¤í¬ I/O
            disk_io = psutil.disk_io_counters()
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            net_io = psutil.net_io_counters()
            
            logger.debug(
                f"Resource usage - "
                f"CPU: {cpu_percent}%, "
                f"Memory: {memory.percent}% ({memory.used / 1024**3:.2f}GB / {memory.total / 1024**3:.2f}GB), "
                f"Disk read: {disk_io.read_bytes / 1024**2:.2f}MB, "
                f"Disk write: {disk_io.write_bytes / 1024**2:.2f}MB"
            )
            
            # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê²½ê³ 
            if cpu_percent > 80:
                logger.warning(f"High CPU usage: {cpu_percent}%")
            if memory.percent > 80:
                logger.warning(f"High memory usage: {memory.percent}%")
            
            time.sleep(5)
```

#### 1.4 ì´ë²¤íŠ¸/ë©”ì‹œì§€ ì²˜ë¦¬ ë¬¸ì œ

**ì¦ìƒ**
- ë©”ì‹œì§€ ì†ì‹¤
- ì¤‘ë³µ ì²˜ë¦¬
- ìˆœì„œ ë¬¸ì œ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë©”ì‹œì§€ ì²˜ë¦¬ ì¶”ì 
class MessageProcessor:
    def __init__(self):
        self.processed_messages = set()  # ì¤‘ë³µ ë°©ì§€
        self.message_order = []  # ìˆœì„œ ì¶”ì 
    
    async def process_message(self, message_id: str, message: dict):
        # ì¤‘ë³µ í™•ì¸
        if message_id in self.processed_messages:
            logger.warning(f"Duplicate message detected: {message_id}")
            return
        
        logger.info(f"Processing message: {message_id}")
        
        try:
            # ë©”ì‹œì§€ ì²˜ë¦¬
            result = await self._handle_message(message)
            
            # ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            self.processed_messages.add(message_id)
            self.message_order.append({
                'id': message_id,
                'timestamp': time.time(),
                'status': 'success'
            })
            
            logger.info(f"Message processed successfully: {message_id}")
            return result
            
        except Exception as e:
            logger.error(
                f"Message processing failed: {message_id}, error: {e}",
                exc_info=True
            )
            self.message_order.append({
                'id': message_id,
                'timestamp': time.time(),
                'status': 'failed',
                'error': str(e)
            })
            raise
```

### 2. ì•„í‚¤í…ì²˜ ë””ë²„ê¹… ì „ëµ

#### 2.1 ë¶„ì‚° ì¶”ì  (Distributed Tracing)

```python
# OpenTelemetryë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° ì¶”ì  ì„¤ì •
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger import JaegerExporter

def setup_tracing(service_name: str):
    trace.set_tracer_provider(TracerProvider())
    
    # Jaegerë¡œ ì¶”ì  ë°ì´í„° ì „ì†¡
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831,
    )
    
    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)
    
    return trace.get_tracer(service_name)

# ì‚¬ìš© ì˜ˆì‹œ
tracer = setup_tracing("order-service")

@app.post("/orders")
async def create_order(order_data: OrderCreate):
    with tracer.start_as_current_span("create_order") as span:
        span.set_attribute("order.items_count", len(order_data.items))
        
        # ë‹¤ë¥¸ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œ ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ
        with tracer.start_as_current_span("call_inventory_service"):
            inventory_result = await inventory_service.check(order_data.items)
        
        return result
```

#### 2.2 í—¬ìŠ¤ ì²´í¬ ë° ëª¨ë‹ˆí„°ë§

```python
# ì¢…í•© í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health")
async def health_check():
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {}
    }
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬
    try:
        await db.execute("SELECT 1")
        health_status["checks"]["database"] = "healthy"
    except Exception as e:
        health_status["checks"]["database"] = f"unhealthy: {e}"
        health_status["status"] = "unhealthy"
    
    # ìºì‹œ ì²´í¬
    try:
        await cache.ping()
        health_status["checks"]["cache"] = "healthy"
    except Exception as e:
        health_status["checks"]["cache"] = f"unhealthy: {e}"
        health_status["status"] = "degraded"
    
    # ì™¸ë¶€ ì„œë¹„ìŠ¤ ì²´í¬
    try:
        response = await external_service.health_check()
        health_status["checks"]["external_service"] = "healthy"
    except Exception as e:
        health_status["checks"]["external_service"] = f"unhealthy: {e}"
        health_status["status"] = "degraded"
    
    status_code = 200 if health_status["status"] == "healthy" else 503
    return JSONResponse(content=health_status, status_code=status_code)
```

#### 2.3 ì˜ì¡´ì„± ê·¸ë˜í”„ ë¶„ì„

```python
# ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì¶”ì 
class DependencyTracker:
    def __init__(self):
        self.dependencies = {}
        self.call_graph = []
    
    def track_call(self, caller: str, callee: str, duration: float, success: bool):
        self.call_graph.append({
            'caller': caller,
            'callee': callee,
            'duration': duration,
            'success': success,
            'timestamp': time.time()
        })
        
        if caller not in self.dependencies:
            self.dependencies[caller] = []
        
        if callee not in self.dependencies[caller]:
            self.dependencies[caller].append(callee)
    
    def get_dependency_graph(self):
        return self.dependencies
    
    def analyze_circular_dependencies(self):
        # ìˆœí™˜ ì˜ì¡´ì„± íƒì§€
        visited = set()
        rec_stack = set()
        cycles = []
        
        def dfs(node, path):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            for neighbor in self.dependencies.get(node, []):
                if neighbor not in visited:
                    dfs(neighbor, path)
                elif neighbor in rec_stack:
                    # ìˆœí™˜ ë°œê²¬
                    cycle_start = path.index(neighbor)
                    cycles.append(path[cycle_start:] + [neighbor])
            
            rec_stack.remove(node)
            path.pop()
        
        for node in self.dependencies:
            if node not in visited:
                dfs(node, [])
        
        return cycles
```

### 3. ì•„í‚¤í…ì²˜ ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ì„œë¹„ìŠ¤ ê°„ í†µì‹ ì´ ì •ìƒì¸ê°€?
â–¡ ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì´ í—ˆìš© ë²”ìœ„ ë‚´ì¸ê°€?
â–¡ íƒ€ì„ì•„ì›ƒ ì„¤ì •ì´ ì ì ˆí•œê°€?
â–¡ ì¬ì‹œë„ ë¡œì§ì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ëŠ”ê°€?
â–¡ ì„œí‚· ë¸Œë ˆì´ì»¤ê°€ í•„ìš”í•  ë§Œí¼ ì‹¤íŒ¨ê°€ ë§ì€ê°€?
â–¡ ë°ì´í„° ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ íŠ¸ëœì­ì…˜ì´ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬ë˜ëŠ”ê°€?
â–¡ ë¶„ì‚° íŠ¸ëœì­ì…˜ì´ í•„ìš”í•œê°€?
â–¡ ì´ë²¤íŠ¸ ìˆœì„œê°€ ë³´ì¥ë˜ëŠ”ê°€?
â–¡ ë©”ì‹œì§€ê°€ ì¤‘ë³µ ì²˜ë¦¬ë˜ì§€ ì•ŠëŠ”ê°€?
â–¡ ë©”ì‹œì§€ê°€ ì†ì‹¤ë˜ì§€ ì•ŠëŠ”ê°€?
â–¡ ìºì‹œì™€ DB ê°„ ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ë¦¬ì†ŒìŠ¤ ê²½í•©ì´ ì—†ëŠ”ê°€?
â–¡ ë°ë“œë½ ê°€ëŠ¥ì„±ì´ ì—†ëŠ”ê°€?
â–¡ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì •ìƒ ë²”ìœ„ì¸ê°€?
â–¡ í™•ì¥ì„± ë¬¸ì œê°€ ì—†ëŠ”ê°€?
â–¡ ë‹¨ì¼ ì¥ì• ì (Single Point of Failure)ì´ ì—†ëŠ”ê°€?
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ê´€ì  ë””ë²„ê¹…

ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í•µì‹¬ ê¸°ëŠ¥ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. 
ì¿¼ë¦¬ ì„±ëŠ¥, íŠ¸ëœì­ì…˜ ê´€ë¦¬, ë°ì´í„° ì¼ê´€ì„± ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ë””ë²„ê¹…í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬ ìœ í˜•

#### 1.1 ì¿¼ë¦¬ ì„±ëŠ¥ ë¬¸ì œ

**ì¦ìƒ**
- ëŠë¦° ì‘ë‹µ ì‹œê°„
- íƒ€ì„ì•„ì›ƒ ë°œìƒ
- ë†’ì€ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
import time
from sqlalchemy import event
from sqlalchemy.engine import Engine

# SQLAlchemy ì¿¼ë¦¬ ë¡œê¹…
@event.listens_for(Engine, "before_cursor_execute")
def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(time.time())
    logger.debug(f"Query: {statement}")
    logger.debug(f"Parameters: {parameters}")

@event.listens_for(Engine, "after_cursor_execute")
def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - conn.info['query_start_time'].pop(-1)
    logger.info(f"Query executed in {total:.3f}s")
    
    # ëŠë¦° ì¿¼ë¦¬ ê²½ê³ 
    if total > 1.0:  # 1ì´ˆ ì´ìƒ
        logger.warning(f"Slow query detected ({total:.3f}s): {statement}")

# Django ORM ì¿¼ë¦¬ ë””ë²„ê¹…
from django.db import connection
from django.conf import settings

if settings.DEBUG:
    # ëª¨ë“  ì¿¼ë¦¬ ë¡œê¹…
    for query in connection.queries:
        logger.debug(f"Query: {query['sql']}, Time: {query['time']}s")
    
    # ëŠë¦° ì¿¼ë¦¬ í™•ì¸
    slow_queries = [q for q in connection.queries if float(q['time']) > 1.0]
    if slow_queries:
        logger.warning(f"Found {len(slow_queries)} slow queries")
```

#### 1.2 íŠ¸ëœì­ì…˜ ë¬¸ì œ

**ì¦ìƒ**
- ë°ì´í„° ë¶ˆì¼ì¹˜
- ë°ë“œë½ ë°œìƒ
- ë¡¤ë°± ì‹¤íŒ¨

**ë””ë²„ê¹… ë°©ë²•**

```python
# íŠ¸ëœì­ì…˜ ì¶”ì 
class TransactionTracker:
    def __init__(self):
        self.active_transactions = {}
        self.transaction_history = []
    
    def start_transaction(self, tx_id: str, operation: str):
        self.active_transactions[tx_id] = {
            'start_time': time.time(),
            'operation': operation,
            'queries': []
        }
        logger.info(f"Transaction started: {tx_id}, operation: {operation}")
    
    def log_query(self, tx_id: str, query: str):
        if tx_id in self.active_transactions:
            self.active_transactions[tx_id]['queries'].append({
                'query': query,
                'time': time.time()
            })
    
    def commit_transaction(self, tx_id: str):
        if tx_id in self.active_transactions:
            tx_info = self.active_transactions.pop(tx_id)
            duration = time.time() - tx_info['start_time']
            
            self.transaction_history.append({
                'tx_id': tx_id,
                'duration': duration,
                'queries_count': len(tx_info['queries']),
                'operation': tx_info['operation']
            })
            
            logger.info(
                f"Transaction committed: {tx_id}, "
                f"duration: {duration:.3f}s, "
                f"queries: {len(tx_info['queries'])}"
            )
    
    def rollback_transaction(self, tx_id: str, reason: str):
        if tx_id in self.active_transactions:
            tx_info = self.active_transactions.pop(tx_id)
            duration = time.time() - tx_info['start_time']
            
            logger.error(
                f"Transaction rolled back: {tx_id}, "
                f"reason: {reason}, "
                f"duration: {duration:.3f}s"
            )

# íŠ¸ëœì­ì…˜ ë°ì½”ë ˆì´í„°
def transactional(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        tx_id = str(uuid.uuid4())
        tracker = TransactionTracker()
        
        tracker.start_transaction(tx_id, func.__name__)
        
        async with db.begin():  # íŠ¸ëœì­ì…˜ ì‹œì‘
            try:
                result = await func(*args, **kwargs)
                tracker.commit_transaction(tx_id)
                return result
            except Exception as e:
                tracker.rollback_transaction(tx_id, str(e))
                raise
    
    return wrapper
```

#### 1.3 ì—°ê²° í’€ ë¬¸ì œ

**ì¦ìƒ**
- ì—°ê²° ë¶€ì¡± ì—ëŸ¬
- ì—°ê²° ëˆ„ìˆ˜
- íƒ€ì„ì•„ì›ƒ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì—°ê²° í’€ ëª¨ë‹ˆí„°ë§
from sqlalchemy import create_engine, event
from sqlalchemy.pool import Pool

@event.listens_for(Pool, "connect")
def receive_connect(dbapi_conn, connection_record):
    logger.debug("New database connection created")
    connection_record.info['created_at'] = time.time()

@event.listens_for(Pool, "checkout")
def receive_checkout(dbapi_conn, connection_record, connection_proxy):
    logger.debug("Connection checked out from pool")
    connection_record.info['checked_out_at'] = time.time()

@event.listens_for(Pool, "checkin")
def receive_checkin(dbapi_conn, connection_record):
    logger.debug("Connection returned to pool")
    if 'checked_out_at' in connection_record.info:
        duration = time.time() - connection_record.info['checked_out_at']
        logger.debug(f"Connection was used for {duration:.3f}s")

@event.listens_for(Pool, "invalidate")
def receive_invalidate(dbapi_conn, connection_record, exception):
    logger.warning(f"Connection invalidated: {exception}")

# ì—°ê²° í’€ ìƒíƒœ í™•ì¸
def check_pool_status(engine):
    pool = engine.pool
    logger.info(
        f"Pool status - "
        f"Size: {pool.size()}, "
        f"Checked out: {pool.checkedout()}, "
        f"Overflow: {pool.overflow()}, "
        f"Checked in: {pool.checkedin()}"
    )
    
    if pool.checkedout() > pool.size() * 0.8:
        logger.warning("High connection pool usage detected")
```

#### 1.4 N+1 ì¿¼ë¦¬ ë¬¸ì œ

**ì¦ìƒ**
- ì˜ˆìƒë³´ë‹¤ ë§ì€ ì¿¼ë¦¬ ì‹¤í–‰
- ëŠë¦° ì‘ë‹µ ì‹œê°„

**ë””ë²„ê¹… ë°©ë²•**

```python
# N+1 ì¿¼ë¦¬ íƒì§€
class QueryCounter:
    def __init__(self):
        self.query_count = 0
        self.queries = []
    
    def count_query(self, query: str):
        self.query_count += 1
        self.queries.append({
            'number': self.query_count,
            'query': query,
            'time': time.time()
        })
    
    def analyze_n_plus_one(self, threshold: int = 10):
        if self.query_count > threshold:
            logger.warning(
                f"Possible N+1 query detected: {self.query_count} queries executed"
            )
            
            # ìœ ì‚¬í•œ ì¿¼ë¦¬ íŒ¨í„´ ì°¾ê¸°
            query_patterns = {}
            for q in self.queries:
                # ì¿¼ë¦¬ì—ì„œ í…Œì´ë¸”ëª… ì¶”ì¶œ
                table_match = re.search(r'FROM\s+(\w+)', q['query'], re.IGNORECASE)
                if table_match:
                    table = table_match.group(1)
                    query_patterns[table] = query_patterns.get(table, 0) + 1
            
            for table, count in query_patterns.items():
                if count > threshold:
                    logger.warning(
                        f"Table {table} queried {count} times - "
                        f"consider using eager loading or batch loading"
                    )

# ì‚¬ìš© ì˜ˆì‹œ
query_counter = QueryCounter()

# ì¿¼ë¦¬ ì‹¤í–‰ ì „
query_counter.count_query("SELECT * FROM users WHERE id = 1")

# ê²°ê³¼ ë¶„ì„
query_counter.analyze_n_plus_one(threshold=5)

# í•´ê²° ë°©ë²•: Eager Loading
# SQLAlchemy
users = session.query(User).options(joinedload(User.orders)).all()

# Django ORM
users = User.objects.select_related('profile').prefetch_related('orders').all()
```

### 2. ë°ì´í„°ë² ì´ìŠ¤ ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ì¿¼ë¦¬ê°€ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
â–¡ ì¿¼ë¦¬ ì‹¤í–‰ ê³„íšì„ í™•ì¸í–ˆëŠ”ê°€? (EXPLAIN)
â–¡ N+1 ì¿¼ë¦¬ ë¬¸ì œê°€ ì—†ëŠ”ê°€?
â–¡ íŠ¸ëœì­ì…˜ì´ ì˜¬ë°”ë¥´ê²Œ ê´€ë¦¬ë˜ëŠ”ê°€?
â–¡ íŠ¸ëœì­ì…˜ ê²©ë¦¬ ìˆ˜ì¤€ì´ ì ì ˆí•œê°€?
â–¡ ë°ë“œë½ ê°€ëŠ¥ì„±ì´ ì—†ëŠ”ê°€?
â–¡ ì—°ê²° í’€ì´ ì ì ˆíˆ ì„¤ì •ë˜ì—ˆëŠ”ê°€?
â–¡ ì—°ê²°ì´ ì œëŒ€ë¡œ ë°˜í™˜ë˜ëŠ”ê°€? (ì—°ê²° ëˆ„ìˆ˜ í™•ì¸)
â–¡ ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¡œê·¸ë¥¼ í™•ì¸í–ˆëŠ”ê°€?
â–¡ ë°ì´í„°ë² ì´ìŠ¤ ë½ì´ ì ì ˆíˆ ì‚¬ìš©ë˜ëŠ”ê°€?
â–¡ ë°°ì¹˜ ì‘ì—…ì´ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ê°€?
```

---

## ë¹„ë™ê¸°/ë™ì‹œì„± ê´€ì  ë””ë²„ê¹…

ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ê³¼ ë™ì‹œì„±ì€ í˜„ëŒ€ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ í•„ìˆ˜ì ì´ì§€ë§Œ, 
ë””ë²„ê¹…ì´ ì–´ë ¤ìš´ ì˜ì—­ì…ë‹ˆë‹¤. ë ˆì´ìŠ¤ ì»¨ë””ì…˜, ë°ë“œë½, ë™ì‹œì„± ë²„ê·¸ ë“±ì„ ì£¼ì˜ ê¹Šê²Œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. ë¹„ë™ê¸°/ë™ì‹œì„± ì—ëŸ¬ ìœ í˜•

#### 1.1 ë ˆì´ìŠ¤ ì»¨ë””ì…˜ (Race Condition)

**ì¦ìƒ**
- ë¹„ê²°ì •ì  ë™ì‘
- ë°ì´í„° ë¶ˆì¼ì¹˜
- ê°„í—ì  ì‹¤íŒ¨

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ì¶”ì 
import asyncio
from collections import defaultdict

class RaceConditionTracker:
    def __init__(self):
        self.shared_resources = defaultdict(list)
        self.access_log = []
    
    def track_access(self, resource_id: str, operation: str, task_id: str):
        timestamp = time.time()
        self.access_log.append({
            'timestamp': timestamp,
            'resource_id': resource_id,
            'operation': operation,
            'task_id': task_id
        })
        
        self.shared_resources[resource_id].append({
            'timestamp': timestamp,
            'operation': operation,
            'task_id': task_id
        })
    
    def detect_race_conditions(self):
        for resource_id, accesses in self.shared_resources.items():
            if len(accesses) < 2:
                continue
            
            # ë™ì‹œ ì ‘ê·¼ íƒì§€ (0.1ì´ˆ ì´ë‚´)
            for i in range(len(accesses) - 1):
                time_diff = accesses[i+1]['timestamp'] - accesses[i]['timestamp']
                if time_diff < 0.1 and accesses[i]['operation'] != accesses[i+1]['operation']:
                    logger.warning(
                        f"Possible race condition detected on {resource_id}: "
                        f"{accesses[i]['operation']} and {accesses[i+1]['operation']} "
                        f"within {time_diff:.3f}s"
                    )

# ë¬¸ì œ ì½”ë“œ ì˜ˆì‹œ
async def update_balance(account_id: str, amount: float):
    # âŒ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ ë°œìƒ ê°€ëŠ¥
    account = await get_account(account_id)
    account.balance += amount
    await save_account(account)

# í•´ê²° ë°©ë²• 1: ë½ ì‚¬ìš©
async def update_balance_with_lock(account_id: str, amount: float):
    async with account_lock:  # ë¹„ë™ê¸° ë½
        account = await get_account(account_id)
        account.balance += amount
        await save_account(account)

# í•´ê²° ë°©ë²• 2: ë°ì´í„°ë² ì´ìŠ¤ ë ˆë²¨ ë½
async def update_balance_with_db_lock(account_id: str, amount: float):
    async with db.begin():
        account = await db.execute(
            select(Account).where(Account.id == account_id).with_for_update()
        )
        account.balance += amount
        await db.commit()
```

#### 1.2 ë°ë“œë½ (Deadlock)

**ì¦ìƒ**
- í”„ë¡œê·¸ë¨ì´ ë©ˆì¶¤
- íƒ€ì„ì•„ì›ƒ ë°œìƒ
- ë¦¬ì†ŒìŠ¤ê°€ í•´ì œë˜ì§€ ì•ŠìŒ

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë°ë“œë½ íƒì§€
import asyncio
from asyncio import Lock

class DeadlockDetector:
    def __init__(self):
        self.lock_acquisitions = {}
        self.wait_graph = defaultdict(set)
    
    def track_lock_acquisition(self, task_id: str, lock_id: str):
        if task_id in self.lock_acquisitions:
            # ì´ë¯¸ ë‹¤ë¥¸ ë½ì„ ë³´ìœ í•˜ê³  ìˆìŒ
            held_lock = self.lock_acquisitions[task_id]
            self.wait_graph[held_lock].add(lock_id)
        
        self.lock_acquisitions[task_id] = lock_id
    
    def detect_deadlock(self):
        # ì‚¬ì´í´ íƒì§€ (ê°„ë‹¨í•œ DFS)
        visited = set()
        rec_stack = set()
        
        def has_cycle(node):
            visited.add(node)
            rec_stack.add(node)
            
            for neighbor in self.wait_graph.get(node, []):
                if neighbor not in visited:
                    if has_cycle(neighbor):
                        return True
                elif neighbor in rec_stack:
                    logger.error(f"Deadlock detected: cycle involving {node} and {neighbor}")
                    return True
            
            rec_stack.remove(node)
            return False
        
        for node in self.wait_graph:
            if node not in visited:
                if has_cycle(node):
                    return True
        return False

# ë½ ìˆœì„œ í†µì¼ (ë°ë“œë½ ë°©ì§€)
# âŒ ì˜ëª»ëœ ì˜ˆ: ë½ ìˆœì„œê°€ ì¼ê´€ë˜ì§€ ì•ŠìŒ
async def transfer_funds(account1, account2, amount):
    async with account1.lock:
        async with account2.lock:  # ë‹¤ë¥¸ ê³³ì—ì„œ ë°˜ëŒ€ ìˆœì„œë¡œ ì ê·¸ë©´ ë°ë“œë½
            # ...

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: í•­ìƒ ID ìˆœì„œë¡œ ë½ íšë“
async def transfer_funds_safe(account1, account2, amount):
    first, second = sorted([account1, account2], key=lambda a: a.id)
    async with first.lock:
        async with second.lock:
            # ...
```

#### 1.3 ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë¬¸ì œ

**ì¦ìƒ**
- ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ ì†ì‹¤
- ë¹„ë™ê¸° í•¨ìˆ˜ê°€ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë¨
- ì´ë²¤íŠ¸ ë£¨í”„ ë¸”ë¡œí‚¹

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ì¶”ì 
import contextvars

request_id_var = contextvars.ContextVar('request_id')

class AsyncContextTracker:
    def __init__(self):
        self.context_history = []
    
    def track_context(self, operation: str):
        context_data = {
            'operation': operation,
            'request_id': request_id_var.get(None),
            'task_name': asyncio.current_task().get_name() if asyncio.current_task() else None,
            'timestamp': time.time()
        }
        self.context_history.append(context_data)
        logger.debug(f"Context: {context_data}")
    
    def verify_context_preservation(self):
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
        for i in range(len(self.context_history) - 1):
            if self.context_history[i]['request_id'] != self.context_history[i+1]['request_id']:
                logger.warning(
                    f"Context lost between {self.context_history[i]['operation']} "
                    f"and {self.context_history[i+1]['operation']}"
                )

# ì´ë²¤íŠ¸ ë£¨í”„ ë¸”ë¡œí‚¹ íƒì§€
def detect_blocking_operations():
    loop = asyncio.get_event_loop()
    
    # ë¸”ë¡œí‚¹ ì‘ì—… íƒì§€
    import sys
    if sys.platform != 'win32':
        import select
        
        def check_blocking():
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ë¸”ë¡œí‚¹ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            ready, _, _ = select.select([], [], [], 0)
            if ready:
                logger.warning("Event loop may be blocked")
        
        # ì£¼ê¸°ì ìœ¼ë¡œ í™•ì¸
        asyncio.create_task(periodic_check(check_blocking, interval=1.0))
```

#### 1.4 ë™ì‹œì„± ì œì–´ ë¬¸ì œ

**ì¦ìƒ**
- ê³µìœ  ìì› ì ‘ê·¼ ì¶©ëŒ
- ë°ì´í„° ì†ì‹¤
- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼

**ë””ë²„ê¹… ë°©ë²•**

```python
# ë™ì‹œ ì‹¤í–‰ ì¶”ì 
class ConcurrencyTracker:
    def __init__(self):
        self.concurrent_operations = defaultdict(int)
        self.operation_timeline = []
    
    def track_operation(self, operation: str, start: bool):
        timestamp = time.time()
        
        if start:
            self.concurrent_operations[operation] += 1
            self.operation_timeline.append({
                'timestamp': timestamp,
                'operation': operation,
                'action': 'start',
                'concurrent_count': sum(self.concurrent_operations.values())
            })
        else:
            self.concurrent_operations[operation] -= 1
            if self.concurrent_operations[operation] == 0:
                del self.concurrent_operations[operation]
            
            self.operation_timeline.append({
                'timestamp': timestamp,
                'operation': operation,
                'action': 'end',
                'concurrent_count': sum(self.concurrent_operations.values())
            })
        
        logger.debug(
            f"Operation {operation} {'started' if start else 'ended'}, "
            f"concurrent: {sum(self.concurrent_operations.values())}"
        )
    
    def analyze_concurrency(self):
        max_concurrent = max(
            (item['concurrent_count'] for item in self.operation_timeline),
            default=0
        )
        logger.info(f"Maximum concurrent operations: {max_concurrent}")
        
        # ë™ì‹œ ì‹¤í–‰ì´ ë§ì€ êµ¬ê°„ ì°¾ê¸°
        high_concurrency_periods = [
            item for item in self.operation_timeline
            if item['concurrent_count'] > 10
        ]
        if high_concurrency_periods:
            logger.warning(
                f"High concurrency detected: {len(high_concurrency_periods)} periods "
                f"with >10 concurrent operations"
            )

# ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•œ ë™ì‹œì„± ì œì–´
class RateLimiter:
    def __init__(self, max_concurrent: int):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.active_count = 0
    
    async def acquire(self):
        await self.semaphore.acquire()
        self.active_count += 1
        logger.debug(f"Semaphore acquired, active: {self.active_count}")
    
    def release(self):
        self.semaphore.release()
        self.active_count -= 1
        logger.debug(f"Semaphore released, active: {self.active_count}")

# ì‚¬ìš© ì˜ˆì‹œ
rate_limiter = RateLimiter(max_concurrent=5)

async def limited_operation():
    await rate_limiter.acquire()
    try:
        # ì‘ì—… ìˆ˜í–‰
        await do_work()
    finally:
        rate_limiter.release()
```

### 2. ë¹„ë™ê¸°/ë™ì‹œì„± ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ë¹„ë™ê¸° í•¨ìˆ˜ê°€ await ì—†ì´ í˜¸ì¶œë˜ì§€ ì•Šì•˜ëŠ”ê°€?
â–¡ ë™ê¸° ë¸”ë¡œí‚¹ ì‘ì—…ì´ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë§‰ì§€ ì•ŠëŠ”ê°€?
â–¡ ê³µìœ  ìì› ì ‘ê·¼ì´ ì ì ˆíˆ ë³´í˜¸ë˜ëŠ”ê°€?
â–¡ ë½ ìˆœì„œê°€ ì¼ê´€ë˜ëŠ”ê°€? (ë°ë“œë½ ë°©ì§€)
â–¡ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ì˜ˆì™¸ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ê³  ì „íŒŒë˜ëŠ”ê°€?
â–¡ íƒ€ì„ì•„ì›ƒì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ë™ì‹œ ì‹¤í–‰ ìˆ˜ê°€ ì œí•œë˜ì–´ ìˆëŠ”ê°€?
â–¡ ë¦¬ì†ŒìŠ¤ê°€ ì ì ˆíˆ í•´ì œë˜ëŠ”ê°€?
â–¡ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ì´ ì—†ëŠ”ê°€?
```

---

## í™˜ê²½/ì„¤ì • ê´€ì  ë””ë²„ê¹…

í™˜ê²½ ë³€ìˆ˜, ì„¤ì • íŒŒì¼, ì˜ì¡´ì„± ë²„ì „ ë“±ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë™ì‘ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. 
í™˜ê²½ë³„ ì°¨ì´ë¡œ ì¸í•œ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë””ë²„ê¹…í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. í™˜ê²½/ì„¤ì • ì—ëŸ¬ ìœ í˜•

#### 1.1 í™˜ê²½ ë³€ìˆ˜ ë¬¸ì œ

**ì¦ìƒ**
- ì„¤ì • ê°’ì´ None ë˜ëŠ” ê¸°ë³¸ê°’
- í™˜ê²½ë³„ë¡œ ë‹¤ë¥¸ ë™ì‘
- ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œ

**ë””ë²„ê¹… ë°©ë²•**

```python
# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
import os
from typing import Optional

class EnvironmentValidator:
    def __init__(self):
        self.required_vars = []
        self.optional_vars = []
        self.validated_vars = {}
    
    def require(self, var_name: str, var_type: type = str, default: Optional[any] = None):
        self.required_vars.append({
            'name': var_name,
            'type': var_type,
            'default': default
        })
    
    def optional(self, var_name: str, var_type: type = str, default: Optional[any] = None):
        self.optional_vars.append({
            'name': var_name,
            'type': var_type,
            'default': default
        })
    
    def validate(self) -> dict:
        missing_vars = []
        
        # í•„ìˆ˜ ë³€ìˆ˜ í™•ì¸
        for var_spec in self.required_vars:
            var_name = var_spec['name']
            var_type = var_spec['type']
            default = var_spec['default']
            
            value = os.getenv(var_name, default)
            
            if value is None:
                missing_vars.append(var_name)
                logger.error(f"Required environment variable missing: {var_name}")
            else:
                try:
                    # íƒ€ì… ë³€í™˜
                    if var_type == bool:
                        value = value.lower() in ('true', '1', 'yes', 'on')
                    elif var_type == int:
                        value = int(value)
                    elif var_type == float:
                        value = float(value)
                    
                    self.validated_vars[var_name] = value
                    logger.debug(f"Environment variable validated: {var_name}")
                except (ValueError, TypeError) as e:
                    logger.error(
                        f"Invalid type for {var_name}: expected {var_type.__name__}, "
                        f"got {type(value).__name__}, error: {e}"
                    )
                    missing_vars.append(var_name)
        
        # ì„ íƒì  ë³€ìˆ˜ í™•ì¸
        for var_spec in self.optional_vars:
            var_name = var_spec['name']
            var_type = var_spec['type']
            default = var_spec['default']
            
            value = os.getenv(var_name, default)
            
            if value is not None:
                try:
                    if var_type == bool:
                        value = value.lower() in ('true', '1', 'yes', 'on')
                    elif var_type == int:
                        value = int(value)
                    elif var_type == float:
                        value = float(value)
                    
                    self.validated_vars[var_name] = value
                except (ValueError, TypeError) as e:
                    logger.warning(
                        f"Invalid type for optional {var_name}: {e}, using default"
                    )
                    self.validated_vars[var_name] = default
        
        if missing_vars:
            raise ValueError(f"Missing required environment variables: {missing_vars}")
        
        return self.validated_vars

# ì‚¬ìš© ì˜ˆì‹œ
validator = EnvironmentValidator()
validator.require('DATABASE_URL', str)
validator.require('REDIS_URL', str)
validator.require('DEBUG', bool, default=False)
validator.optional('LOG_LEVEL', str, default='INFO')

config = validator.validate()
```

#### 1.2 ì„¤ì • íŒŒì¼ ë¬¸ì œ

**ì¦ìƒ**
- ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
- ì„¤ì • í˜•ì‹ ì˜¤ë¥˜
- í™˜ê²½ë³„ ì„¤ì • ë¶ˆì¼ì¹˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì„¤ì • íŒŒì¼ ë¡œë”© ë° ê²€ì¦
import json
import yaml
from pathlib import Path
from typing import Dict, Any

class ConfigLoader:
    def __init__(self, config_path: str):
        self.config_path = Path(config_path)
        self.config = {}
        self.loaded_files = []
    
    def load(self) -> Dict[str, Any]:
        if not self.config_path.exists():
            raise FileNotFoundError(f"Config file not found: {self.config_path}")
        
        logger.info(f"Loading config from: {self.config_path}")
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ë¡œë” ì„ íƒ
        if self.config_path.suffix == '.json':
            with open(self.config_path) as f:
                self.config = json.load(f)
        elif self.config_path.suffix in ['.yaml', '.yml']:
            with open(self.config_path) as f:
                self.config = yaml.safe_load(f)
        else:
            raise ValueError(f"Unsupported config file format: {self.config_path.suffix}")
        
        self.loaded_files.append(str(self.config_path))
        logger.debug(f"Config loaded: {len(self.config)} keys")
        
        return self.config
    
    def validate(self, schema: Dict[str, Any]):
        """ì„¤ì • ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
        missing_keys = []
        invalid_types = []
        
        def validate_recursive(config: Dict, schema: Dict, path: str = ""):
            for key, expected_type in schema.items():
                current_path = f"{path}.{key}" if path else key
                
                if key not in config:
                    missing_keys.append(current_path)
                    continue
                
                value = config[key]
                
                if isinstance(expected_type, dict):
                    # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬
                    if not isinstance(value, dict):
                        invalid_types.append(f"{current_path}: expected dict, got {type(value).__name__}")
                    else:
                        validate_recursive(value, expected_type, current_path)
                elif isinstance(expected_type, type):
                    # íƒ€ì… ê²€ì¦
                    if not isinstance(value, expected_type):
                        invalid_types.append(
                            f"{current_path}: expected {expected_type.__name__}, "
                            f"got {type(value).__name__}"
                        )
        
        validate_recursive(self.config, schema)
        
        if missing_keys:
            logger.error(f"Missing config keys: {missing_keys}")
        if invalid_types:
            logger.error(f"Invalid config types: {invalid_types}")
        
        if missing_keys or invalid_types:
            raise ValueError("Config validation failed")
        
        logger.info("Config validation passed")
    
    def get(self, key: str, default: Any = None) -> Any:
        """ì  í‘œê¸°ë²•ìœ¼ë¡œ ì¤‘ì²©ëœ í‚¤ ì ‘ê·¼"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        
        return value

# í™˜ê²½ë³„ ì„¤ì • ë¡œë”©
def load_environment_config(env: str = None) -> Dict[str, Any]:
    if env is None:
        env = os.getenv('ENVIRONMENT', 'development')
    
    base_config_path = Path('config') / 'base.yaml'
    env_config_path = Path('config') / f'{env}.yaml'
    
    config = {}
    
    # ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    if base_config_path.exists():
        base_loader = ConfigLoader(base_config_path)
        config.update(base_loader.load())
        logger.info(f"Loaded base config: {base_config_path}")
    
    # í™˜ê²½ë³„ ì„¤ì • ë¡œë“œ (ê¸°ë³¸ ì„¤ì •ì„ ë®ì–´ì”€)
    if env_config_path.exists():
        env_loader = ConfigLoader(env_config_path)
        env_config = env_loader.load()
        config = merge_config(config, env_config)
        logger.info(f"Loaded environment config: {env_config_path}")
    else:
        logger.warning(f"Environment config not found: {env_config_path}")
    
    return config
```

#### 1.3 ì˜ì¡´ì„± ë²„ì „ ë¬¸ì œ

**ì¦ìƒ**
- íŒ¨í‚¤ì§€ ë²„ì „ ë¶ˆì¼ì¹˜
- í˜¸í™˜ì„± ë¬¸ì œ
- ê¸°ëŠ¥ì´ ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë™ì‘

**ë””ë²„ê¹… ë°©ë²•**

```python
# ì˜ì¡´ì„± ë²„ì „ í™•ì¸
import importlib.metadata
from packaging import version

class DependencyChecker:
    def __init__(self):
        self.installed_packages = {}
        self.required_packages = {}
    
    def check_installed(self, package_name: str) -> Optional[str]:
        """ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸"""
        try:
            dist = importlib.metadata.distribution(package_name)
            version = dist.version
            self.installed_packages[package_name] = version
            return version
        except importlib.metadata.PackageNotFoundError:
            logger.warning(f"Package not installed: {package_name}")
            return None
    
    def require(self, package_name: str, min_version: str = None, max_version: str = None):
        """í•„ìˆ˜ íŒ¨í‚¤ì§€ ë° ë²„ì „ ìš”êµ¬ì‚¬í•­ ë“±ë¡"""
        self.required_packages[package_name] = {
            'min': min_version,
            'max': max_version
        }
    
    def validate_all(self) -> Dict[str, bool]:
        """ëª¨ë“  ì˜ì¡´ì„± ê²€ì¦"""
        results = {}
        
        for package_name, requirements in self.required_packages.items():
            installed_version = self.check_installed(package_name)
            
            if installed_version is None:
                logger.error(f"Required package not installed: {package_name}")
                results[package_name] = False
                continue
            
            # ë²„ì „ ê²€ì¦
            is_valid = True
            
            if requirements['min']:
                if version.parse(installed_version) < version.parse(requirements['min']):
                    logger.error(
                        f"{package_name}: installed {installed_version}, "
                        f"required >= {requirements['min']}"
                    )
                    is_valid = False
            
            if requirements['max']:
                if version.parse(installed_version) > version.parse(requirements['max']):
                    logger.error(
                        f"{package_name}: installed {installed_version}, "
                        f"required <= {requirements['max']}"
                    )
                    is_valid = False
            
            if is_valid:
                logger.info(
                    f"{package_name}: {installed_version} âœ“ "
                    f"(required: {requirements['min'] or 'any'} - {requirements['max'] or 'any'})"
                )
            
            results[package_name] = is_valid
        
        return results

# ì‚¬ìš© ì˜ˆì‹œ
checker = DependencyChecker()
checker.require('fastapi', min_version='0.100.0')
checker.require('sqlalchemy', min_version='2.0.0', max_version='2.1.0')
checker.require('pydantic', min_version='2.0.0')

results = checker.validate_all()
if not all(results.values()):
    raise RuntimeError("Dependency validation failed")
```

### 2. í™˜ê²½/ì„¤ì • ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ëª¨ë‘ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ í™˜ê²½ ë³€ìˆ˜ íƒ€ì…ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ ì„¤ì • íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ê°€?
â–¡ ì„¤ì • íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ í™˜ê²½ë³„ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ëŠ”ê°€?
â–¡ ì˜ì¡´ì„± ë²„ì „ì´ í˜¸í™˜ë˜ëŠ”ê°€?
â–¡ ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ êµ¬ë¶„ë˜ëŠ”ê°€?
â–¡ ë¯¼ê°í•œ ì •ë³´ê°€ ì½”ë“œì— í•˜ë“œì½”ë”©ë˜ì§€ ì•Šì•˜ëŠ”ê°€?
â–¡ ê¸°ë³¸ê°’ì´ ì ì ˆíˆ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ì„¤ì • ë³€ê²½ ì‹œ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¬ì‹œì‘ë˜ëŠ”ê°€?
```

---

## ìºì‹œ ê´€ì  ë””ë²„ê¹…

ìºì‹œëŠ” ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ í•„ìˆ˜ì ì´ì§€ë§Œ, ì˜ëª» ì‚¬ìš©í•˜ë©´ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
ìºì‹œ ë¬´íš¨í™”, TTL, ì¼ê´€ì„± ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ë””ë²„ê¹…í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. ìºì‹œ ì—ëŸ¬ ìœ í˜•

#### 1.1 ìºì‹œ ë¬´íš¨í™” ë¬¸ì œ

**ì¦ìƒ**
- ì˜¤ë˜ëœ ë°ì´í„° í‘œì‹œ
- ì—…ë°ì´íŠ¸ê°€ ë°˜ì˜ë˜ì§€ ì•ŠìŒ
- ë°ì´í„° ë¶ˆì¼ì¹˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ìºì‹œ ì¶”ì 
class CacheTracker:
    def __init__(self):
        self.cache_operations = []
        self.cache_keys = {}
    
    def track_get(self, key: str, hit: bool, value: Any = None):
        operation = {
            'type': 'get',
            'key': key,
            'hit': hit,
            'timestamp': time.time(),
            'value_hash': hash(str(value)) if value else None
        }
        self.cache_operations.append(operation)
        
        if hit:
            logger.debug(f"Cache HIT: {key}")
        else:
            logger.debug(f"Cache MISS: {key}")
    
    def track_set(self, key: str, value: Any, ttl: int = None):
        operation = {
            'type': 'set',
            'key': key,
            'ttl': ttl,
            'timestamp': time.time(),
            'value_hash': hash(str(value))
        }
        self.cache_operations.append(operation)
        self.cache_keys[key] = {
            'set_at': time.time(),
            'ttl': ttl,
            'expires_at': time.time() + ttl if ttl else None
        }
        logger.debug(f"Cache SET: {key}, TTL: {ttl}")
    
    def track_delete(self, key: str):
        operation = {
            'type': 'delete',
            'key': key,
            'timestamp': time.time()
        }
        self.cache_operations.append(operation)
        
        if key in self.cache_keys:
            del self.cache_keys[key]
        
        logger.debug(f"Cache DELETE: {key}")
    
    def analyze_invalidation(self):
        """ìºì‹œ ë¬´íš¨í™” íŒ¨í„´ ë¶„ì„"""
        # SET í›„ DELETEê°€ ì—†ëŠ” í‚¤ ì°¾ê¸°
        set_keys = set()
        delete_keys = set()
        
        for op in self.cache_operations:
            if op['type'] == 'set':
                set_keys.add(op['key'])
            elif op['type'] == 'delete':
                delete_keys.add(op['key'])
        
        never_invalidated = set_keys - delete_keys
        if never_invalidated:
            logger.warning(
                f"Cache keys never invalidated: {never_invalidated}. "
                f"Consider adding invalidation logic."
            )
        
        # GET í›„ SETê°€ ì—†ëŠ” í‚¤ ì°¾ê¸° (ìºì‹œ ë¯¸ìŠ¤ í›„ ì—…ë°ì´íŠ¸ ì•ˆ ë¨)
        get_keys = {}
        for op in self.cache_operations:
            if op['type'] == 'get' and not op['hit']:
                if op['key'] not in get_keys:
                    get_keys[op['key']] = []
                get_keys[op['key']].append(op['timestamp'])
        
        for key, miss_times in get_keys.items():
            # MISS í›„ SETì´ ìˆëŠ”ì§€ í™•ì¸
            has_set_after_miss = any(
                op['type'] == 'set' and op['key'] == key and op['timestamp'] > miss_time
                for op in self.cache_operations
                for miss_time in miss_times
            )
            
            if not has_set_after_miss and len(miss_times) > 5:
                logger.warning(
                    f"Cache key {key} has {len(miss_times)} misses but no subsequent SET. "
                    f"Consider implementing cache-aside pattern."
                )

# ìºì‹œ ë¬´íš¨í™” ì „ëµ
class CacheInvalidator:
    def __init__(self, cache_client):
        self.cache = cache_client
        self.invalidation_rules = {}
    
    def register_invalidation_rule(self, pattern: str, invalidate_keys: callable):
        """ë¬´íš¨í™” ê·œì¹™ ë“±ë¡"""
        self.invalidation_rules[pattern] = invalidate_keys
    
    def invalidate_on_update(self, entity_type: str, entity_id: str):
        """ì—”í‹°í‹° ì—…ë°ì´íŠ¸ ì‹œ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
        keys_to_invalidate = []
        
        # íŒ¨í„´ ê¸°ë°˜ ë¬´íš¨í™”
        for pattern, get_keys_func in self.invalidation_rules.items():
            if pattern in entity_type:
                keys = get_keys_func(entity_type, entity_id)
                keys_to_invalidate.extend(keys)
        
        # ì¼ë°˜ì ì¸ í‚¤ íŒ¨í„´
        keys_to_invalidate.extend([
            f"{entity_type}:{entity_id}",
            f"{entity_type}:{entity_id}:*",  # ì™€ì¼ë“œì¹´ë“œ
        ])
        
        for key in keys_to_invalidate:
            if '*' in key:
                # ì™€ì¼ë“œì¹´ë“œ ì‚­ì œ (Redisì˜ ê²½ìš°)
                self.cache.delete_pattern(key)
            else:
                self.cache.delete(key)
            
            logger.info(f"Cache invalidated: {key}")
```

#### 1.2 TTL ë¬¸ì œ

**ì¦ìƒ**
- ìºì‹œê°€ ë„ˆë¬´ ë¹¨ë¦¬ ë§Œë£Œë¨
- ìºì‹œê°€ ë„ˆë¬´ ì˜¤ë˜ ìœ ì§€ë¨
- ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë§Œë£Œ ì‹œê°„

**ë””ë²„ê¹… ë°©ë²•**

```python
# TTL ëª¨ë‹ˆí„°ë§
class TTLMonitor:
    def __init__(self):
        self.key_ttls = {}
        self.expiration_events = []
    
    def track_ttl(self, key: str, ttl: int):
        expires_at = time.time() + ttl
        self.key_ttls[key] = {
            'ttl': ttl,
            'set_at': time.time(),
            'expires_at': expires_at
        }
        
        self.expiration_events.append({
            'key': key,
            'expires_at': expires_at
        })
        
        logger.debug(f"TTL set for {key}: {ttl}s, expires at {expires_at}")
    
    def check_expired_keys(self):
        """ë§Œë£Œëœ í‚¤ í™•ì¸"""
        current_time = time.time()
        expired_keys = [
            key for key, info in self.key_ttls.items()
            if info['expires_at'] < current_time
        ]
        
        if expired_keys:
            logger.info(f"Expired cache keys: {expired_keys}")
        
        return expired_keys
    
    def analyze_ttl_patterns(self):
        """TTL íŒ¨í„´ ë¶„ì„"""
        ttls = [info['ttl'] for info in self.key_ttls.values()]
        
        if not ttls:
            return
        
        avg_ttl = sum(ttls) / len(ttls)
        min_ttl = min(ttls)
        max_ttl = max(ttls)
        
        logger.info(
            f"TTL statistics - "
            f"Average: {avg_ttl:.1f}s, "
            f"Min: {min_ttl}s, "
            f"Max: {max_ttl}s"
        )
        
        # ë§¤ìš° ì§§ì€ TTL ê²½ê³ 
        very_short_ttls = [ttl for ttl in ttls if ttl < 60]
        if very_short_ttls:
            logger.warning(
                f"Very short TTLs detected ({len(very_short_ttls)} keys < 60s). "
                f"Consider increasing TTL for better cache hit rate."
            )
        
        # ë§¤ìš° ê¸´ TTL ê²½ê³ 
        very_long_ttls = [ttl for ttl in ttls if ttl > 86400]  # 24ì‹œê°„
        if very_long_ttls:
            logger.warning(
                f"Very long TTLs detected ({len(very_long_ttls)} keys > 24h). "
                f"Consider shorter TTL for better data freshness."
            )
```

#### 1.3 ìºì‹œ ì¼ê´€ì„± ë¬¸ì œ

**ì¦ìƒ**
- ìºì‹œì™€ DB ë°ì´í„° ë¶ˆì¼ì¹˜
- ë™ì‹œ ì—…ë°ì´íŠ¸ ì‹œ ë°ì´í„° ì†ì‹¤
- ì½ê¸°/ì“°ê¸° ë¶ˆì¼ì¹˜

**ë””ë²„ê¹… ë°©ë²•**

```python
# ìºì‹œ ì¼ê´€ì„± ê²€ì¦
class CacheConsistencyChecker:
    def __init__(self, cache_client, db_client):
        self.cache = cache_client
        self.db = db_client
        self.inconsistencies = []
    
    async def verify_consistency(self, key: str, db_fetch_func: callable):
        """ìºì‹œì™€ DB ì¼ê´€ì„± í™•ì¸"""
        cache_value = await self.cache.get(key)
        db_value = await db_fetch_func()
        
        if cache_value != db_value:
            inconsistency = {
                'key': key,
                'cache_value': cache_value,
                'db_value': db_value,
                'timestamp': time.time()
            }
            self.inconsistencies.append(inconsistency)
            
            logger.error(
                f"Cache inconsistency detected for {key}: "
                f"cache={cache_value}, db={db_value}"
            )
            
            return False
        
        return True
    
    def get_inconsistencies(self):
        return self.inconsistencies
    
    def clear_inconsistencies(self):
        self.inconsistencies.clear()

# ìºì‹œ ì „ëµ ì„ íƒ
class CacheStrategy:
    """ì ì ˆí•œ ìºì‹œ ì „ëµ ì„ íƒ"""
    
    @staticmethod
    def cache_aside(key: str, fetch_func: callable, ttl: int = 3600):
        """Cache-Aside íŒ¨í„´"""
        # 1. ìºì‹œì—ì„œ ì¡°íšŒ
        value = cache.get(key)
        if value is not None:
            return value
        
        # 2. ìºì‹œ ë¯¸ìŠ¤ ì‹œ DBì—ì„œ ì¡°íšŒ
        value = fetch_func()
        
        # 3. ìºì‹œì— ì €ì¥
        cache.set(key, value, ttl=ttl)
        
        return value
    
    @staticmethod
    def write_through(key: str, value: Any, save_func: callable, ttl: int = 3600):
        """Write-Through íŒ¨í„´"""
        # 1. DBì— ì €ì¥
        save_func(value)
        
        # 2. ìºì‹œì— ì €ì¥
        cache.set(key, value, ttl=ttl)
    
    @staticmethod
    def write_back(key: str, value: Any, save_func: callable, ttl: int = 3600):
        """Write-Back íŒ¨í„´ (ì£¼ì˜: ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥)"""
        # 1. ìºì‹œì—ë§Œ ì €ì¥ (ì§€ì—° ì“°ê¸°)
        cache.set(key, value, ttl=ttl)
        
        # 2. ë°±ê·¸ë¼ìš´ë“œì—ì„œ DBì— ì €ì¥
        async def background_save():
            await asyncio.sleep(1)  # ì§§ì€ ì§€ì—°
            save_func(value)
        
        asyncio.create_task(background_save())
```

### 2. ìºì‹œ ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ìºì‹œ í‚¤ê°€ ì¼ê´€ëœ í˜•ì‹ì¸ê°€?
â–¡ ìºì‹œ ë¬´íš¨í™”ê°€ ì ì ˆí•œ ì‹œì ì— ì´ë£¨ì–´ì§€ëŠ”ê°€?
â–¡ TTLì´ ì ì ˆíˆ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ìºì‹œì™€ DB ê°„ ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ìºì‹œ ì „ëµì´ ì ì ˆí•œê°€? (Cache-Aside, Write-Through ë“±)
â–¡ ìºì‹œ íˆíŠ¸ìœ¨ì´ ì ì ˆí•œê°€?
â–¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì ì ˆí•œê°€?
â–¡ ìºì‹œ í‚¤ ì¶©ëŒì´ ì—†ëŠ”ê°€?
â–¡ ë¶„ì‚° í™˜ê²½ì—ì„œ ìºì‹œ ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ìºì‹œ ì¥ì•  ì‹œ í´ë°± ì „ëµì´ ìˆëŠ”ê°€?
```

---

## ë””ë²„ê¹… ë„êµ¬ ë° ê¸°ë²•

### 1. ë¡œê¹… ì „ëµ

#### 1.1 êµ¬ì¡°í™”ëœ ë¡œê¹…

```python
import logging
import json
from datetime import datetime

class StructuredLogger:
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
    
    def log(self, level: str, message: str, **kwargs):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": level,
            "message": message,
            **kwargs
        }
        
        log_message = json.dumps(log_data)
        
        if level == "DEBUG":
            self.logger.debug(log_message)
        elif level == "INFO":
            self.logger.info(log_message)
        elif level == "WARNING":
            self.logger.warning(log_message)
        elif level == "ERROR":
            self.logger.error(log_message)
        elif level == "CRITICAL":
            self.logger.critical(log_message)

# ì‚¬ìš© ì˜ˆì‹œ
logger = StructuredLogger(__name__)
logger.log("INFO", "Order created", order_id="123", user_id="456", amount=100.0)
```

#### 1.2 ë¡œê·¸ ë ˆë²¨ ì „ëµ

```python
# ë¡œê·¸ ë ˆë²¨ë³„ ì‚¬ìš© ê°€ì´ë“œ

# DEBUG: ìƒì„¸í•œ ë””ë²„ê¹… ì •ë³´
logger.debug(f"Processing item: {item}, with context: {context}")

# INFO: ì¼ë°˜ì ì¸ ì •ë³´ì„± ë©”ì‹œì§€
logger.info(f"Order {order_id} created successfully")

# WARNING: ì ì¬ì  ë¬¸ì œ (ê¸°ëŠ¥ì€ ë™ì‘í•˜ì§€ë§Œ ì£¼ì˜ í•„ìš”)
logger.warning(f"High memory usage: {memory_percent}%")

# ERROR: ì—ëŸ¬ ë°œìƒ (ê¸°ëŠ¥ ì‹¤íŒ¨)
logger.error(f"Failed to process order: {order_id}", exc_info=True)

# CRITICAL: ì‹¬ê°í•œ ë¬¸ì œ (ì‹œìŠ¤í…œ ì¤‘ë‹¨ ê°€ëŠ¥ì„±)
logger.critical(f"Database connection lost")
```

### 2. ë””ë²„ê±° ì‚¬ìš©

#### 2.1 Python ë””ë²„ê±° (pdb)

```python
# ì½”ë“œì— ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ì„¤ì •
import pdb

def problematic_function(data):
    pdb.set_trace()  # ì—¬ê¸°ì„œ ì‹¤í–‰ì´ ë©ˆì¶¤
    # ë””ë²„ê±° ëª…ë ¹ì–´:
    # n (next): ë‹¤ìŒ ì¤„
    # s (step): í•¨ìˆ˜ ë‚´ë¶€ë¡œ ë“¤ì–´ê°€ê¸°
    # c (continue): ê³„ì† ì‹¤í–‰
    # p variable: ë³€ìˆ˜ ê°’ ì¶œë ¥
    # l (list): í˜„ì¬ ì½”ë“œ ë³´ê¸°
    # q (quit): ì¢…ë£Œ
    
    result = process(data)
    return result
```

#### 2.2 IPython ë””ë²„ê±° (ipdb)

```python
# ë” ê°•ë ¥í•œ ë””ë²„ê±°
import ipdb

def problematic_function(data):
    ipdb.set_trace()  # IPython ê¸°ë°˜ ë””ë²„ê±°
    # ì¶”ê°€ ê¸°ëŠ¥:
    # íƒ­ ìë™ì™„ì„±
    # ìƒ‰ìƒ ì¶œë ¥
    # ë” ë‚˜ì€ ë³€ìˆ˜ íƒìƒ‰
```

#### 2.3 VS Code / PyCharm ë””ë²„ê±°

```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: FastAPI",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/main.py",
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "justMyCode": false
        }
    ]
}
```

### 3. í”„ë¡œíŒŒì¼ë§

#### 3.1 cProfile ì‚¬ìš©

```python
import cProfile
import pstats

# í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
profiler = cProfile.Profile()
profiler.enable()

# í”„ë¡œíŒŒì¼ë§í•  ì½”ë“œ ì‹¤í–‰
your_function()

profiler.disable()

# ê²°ê³¼ ì €ì¥
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)  # ìƒìœ„ 20ê°œ í•¨ìˆ˜
```

#### 3.2 line_profiler ì‚¬ìš©

```python
# í•¨ìˆ˜ì— ë°ì½”ë ˆì´í„° ì¶”ê°€
@profile
def slow_function():
    # ê° ì¤„ì˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    result = expensive_operation()
    return result

# ì‹¤í–‰: kernprof -l -v script.py
```

### 4. ë©”ëª¨ë¦¬ ë””ë²„ê¹…

#### 4.1 memory_profiler ì‚¬ìš©

```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    large_list = [i for i in range(1000000)]
    return sum(large_list)

# ì‹¤í–‰: python -m memory_profiler script.py
```

#### 4.2 tracemalloc ì‚¬ìš©

```python
import tracemalloc

tracemalloc.start()

# ì½”ë“œ ì‹¤í–‰
your_code()

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
current, peak = tracemalloc.get_traced_memory()
print(f"Current memory usage: {current / 1024 / 1024:.2f} MB")
print(f"Peak memory usage: {peak / 1024 / 1024:.2f} MB")

# ìƒìœ„ ë©”ëª¨ë¦¬ ì‚¬ìš©ì í™•ì¸
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:10]:
    print(stat)
```

### 5. ë„¤íŠ¸ì›Œí¬ ë””ë²„ê¹…

#### 5.1 HTTP ìš”ì²­ ì¶”ì 

```python
import httpx
import logging

# HTTP í´ë¼ì´ì–¸íŠ¸ì— ë¡œê¹… ì¶”ê°€
logging.basicConfig(level=logging.DEBUG)

# httpxëŠ” ìë™ìœ¼ë¡œ ìš”ì²­/ì‘ë‹µì„ ë¡œê¹…
client = httpx.Client()
response = client.get("https://api.example.com/data")
```

#### 5.2 gRPC ë””ë²„ê¹…

```python
import grpc
from grpc_interceptor import ServerInterceptor

class LoggingInterceptor(ServerInterceptor):
    def intercept(self, method, request, context, method_name):
        logger.info(f"gRPC call: {method_name}")
        logger.debug(f"Request: {request}")
        
        try:
            response = method(request, context)
            logger.debug(f"Response: {response}")
            return response
        except Exception as e:
            logger.error(f"gRPC error in {method_name}: {e}", exc_info=True)
            raise
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¬¸ì œ ë°œìƒ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### 1ë‹¨ê³„: Import í™•ì¸
```
â–¡ ëª¨ë“ˆì´ ì¡´ì¬í•˜ëŠ”ê°€?
â–¡ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ê°€?
â–¡ ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ìˆœí™˜ ì°¸ì¡°ê°€ ì—†ëŠ”ê°€?
â–¡ Python ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ê°€?
```

#### 2ë‹¨ê³„: ë¡œì§ í™•ì¸
```
â–¡ ì…ë ¥ ê°’ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ ëª¨ë“  ë¶„ê¸°ê°€ í…ŒìŠ¤íŠ¸ë˜ì—ˆëŠ”ê°€?
â–¡ ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì ì ˆí•œê°€?
â–¡ ìƒíƒœ ê´€ë¦¬ê°€ ì˜¬ë°”ë¥¸ê°€?
â–¡ ë°ì´í„° ë³€í™˜ì´ ì˜¬ë°”ë¥¸ê°€?
```

#### 3ë‹¨ê³„: Endpoint í™•ì¸
```
â–¡ ìš”ì²­ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ ì¸ì¦/ì¸ê°€ê°€ í†µê³¼í–ˆëŠ”ê°€?
â–¡ ê²€ì¦ì´ í†µê³¼í–ˆëŠ”ê°€?
â–¡ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ì´ í†µê³¼í–ˆëŠ”ê°€?
â–¡ ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥¸ê°€?
```

#### 4ë‹¨ê³„: ì•„í‚¤í…ì²˜ í™•ì¸
```
â–¡ ì„œë¹„ìŠ¤ ê°„ í†µì‹ ì´ ì •ìƒì¸ê°€?
â–¡ ë°ì´í„° ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì •ìƒì¸ê°€?
â–¡ ì´ë²¤íŠ¸/ë©”ì‹œì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬ë˜ëŠ”ê°€?
â–¡ ì˜ì¡´ì„±ì´ ì˜¬ë°”ë¥¸ê°€?
```

#### 5ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
```
â–¡ ì¿¼ë¦¬ê°€ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
â–¡ N+1 ì¿¼ë¦¬ ë¬¸ì œê°€ ì—†ëŠ”ê°€?
â–¡ íŠ¸ëœì­ì…˜ì´ ì˜¬ë°”ë¥´ê²Œ ê´€ë¦¬ë˜ëŠ”ê°€?
â–¡ ì—°ê²° í’€ì´ ì ì ˆíˆ ì„¤ì •ë˜ì—ˆëŠ”ê°€?
â–¡ ìŠ¬ë¡œìš° ì¿¼ë¦¬ê°€ ì—†ëŠ”ê°€?
```

#### 6ë‹¨ê³„: ë¹„ë™ê¸°/ë™ì‹œì„± í™•ì¸
```
â–¡ ë ˆì´ìŠ¤ ì»¨ë””ì…˜ì´ ì—†ëŠ”ê°€?
â–¡ ë°ë“œë½ ê°€ëŠ¥ì„±ì´ ì—†ëŠ”ê°€?
â–¡ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ê°€ ìœ ì§€ë˜ëŠ”ê°€?
â–¡ ë™ì‹œ ì‹¤í–‰ ìˆ˜ê°€ ì œí•œë˜ì–´ ìˆëŠ”ê°€?
```

#### 7ë‹¨ê³„: í™˜ê²½/ì„¤ì • í™•ì¸
```
â–¡ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ì„¤ì • íŒŒì¼ì´ ì˜¬ë°”ë¥¸ê°€?
â–¡ ì˜ì¡´ì„± ë²„ì „ì´ í˜¸í™˜ë˜ëŠ”ê°€?
```

#### 8ë‹¨ê³„: ìºì‹œ í™•ì¸
```
â–¡ ìºì‹œ ë¬´íš¨í™”ê°€ ì ì ˆí•œê°€?
â–¡ TTLì´ ì ì ˆíˆ ì„¤ì •ë˜ì–´ ìˆëŠ”ê°€?
â–¡ ìºì‹œì™€ DB ê°„ ì¼ê´€ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?
```

### ë””ë²„ê¹… ì„¸ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
â–¡ ë¬¸ì œë¥¼ ì¬í˜„í•  ìˆ˜ ìˆëŠ”ê°€?
â–¡ ì¬í˜„ ë‹¨ê³„ê°€ ë¬¸ì„œí™”ë˜ì—ˆëŠ”ê°€?
â–¡ ê´€ë ¨ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í–ˆëŠ”ê°€?
â–¡ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ê¸°ë¡í–ˆëŠ”ê°€?
â–¡ í™˜ê²½ ì •ë³´ë¥¼ ê¸°ë¡í–ˆëŠ”ê°€? (OS, Python ë²„ì „, íŒ¨í‚¤ì§€ ë²„ì „ ë“±)
â–¡ ê°€ì„¤ì„ ì„¤ì •í•˜ê³  ê²€ì¦í–ˆëŠ”ê°€?
â–¡ í•´ê²° ë°©ë²•ì„ ë¬¸ì„œí™”í–ˆëŠ”ê°€?
â–¡ ìœ ì‚¬ ë¬¸ì œ ì˜ˆë°© ë°©ì•ˆì„ ìˆ˜ë¦½í–ˆëŠ”ê°€?
```

---

## ê²°ë¡ 

ë””ë²„ê¹…ì€ ì²´ê³„ì ì¸ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. 
Import â†’ ë¡œì§ â†’ Endpoint â†’ ì•„í‚¤í…ì²˜ â†’ ë°ì´í„°ë² ì´ìŠ¤ â†’ ë¹„ë™ê¸°/ë™ì‹œì„± â†’ í™˜ê²½/ì„¤ì • â†’ ìºì‹œ ìˆœì„œë¡œ ë¬¸ì œë¥¼ ì¢í˜€ê°€ë©°, 
ê° ë‹¨ê³„ì—ì„œ ì ì ˆí•œ ë„êµ¬ì™€ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í•µì‹¬ ì›ì¹™

1. **ì²´ê³„ì  ì ‘ê·¼**: ë¬¸ì œë¥¼ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„
2. **ì¦ê±° ìˆ˜ì§‘**: ë¡œê·¸, ì—ëŸ¬, ìƒíƒœ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ìˆ˜ì§‘
3. **ê°€ì„¤ ê²€ì¦**: ê°€ëŠ¥í•œ ì›ì¸ì„ ê°€ì„¤ë¡œ ì„¤ì •í•˜ê³  ê²€ì¦
4. **ë„êµ¬ í™œìš©**: ì ì ˆí•œ ë””ë²„ê¹… ë„êµ¬ë¥¼ í™œìš©
5. **ë¬¸ì„œí™”**: ë¬¸ì œì™€ í•´ê²° ë°©ë²•ì„ ë¬¸ì„œí™”í•˜ì—¬ ì¬ë°œ ë°©ì§€

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Python Debugging Guide](https://docs.python.org/3/library/pdb.html)
- [Logging Best Practices](https://docs.python.org/3/howto/logging.html)
- [Distributed Tracing](https://opentelemetry.io/)
- [Performance Profiling](https://docs.python.org/3/library/profile.html)

